{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc, average_precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from skimage import exposure, feature, transform\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28) y_train shape:  (60000,)\n",
      "x test.shape:  (10000, 28, 28)  y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Datensätze (Grauwertbilder) laden. Die Bilder haben eine Größe von 28x28 Pixel und sind bereits segmentiert, \n",
    "jedes enthält nur ein Kleidungsstück\n",
    "\n",
    "Label Beschreibung\n",
    "0     T-shirt/top\n",
    "1     Trousers\n",
    "2     Pullover\n",
    "3     Dress\n",
    "4     Coat\n",
    "5     Sandal\n",
    "6     Shirt\n",
    "7     Sneaker\n",
    "8     Bag\n",
    "9     Ankle boot\n",
    "''' \n",
    "\n",
    "# Trainingsmenge (60.000 Bilder, gelabelt) und Testmenge (10.000 Bilder, gelabelt) laden, \n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"x_train shape: \", X_train.shape, \"y_train shape: \", y_train.shape)\n",
    "print(\"x test.shape: \", X_test.shape, \" y_test shape: \", y_test.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "Normalisieren von [0,255] nach [0,1]\n",
    "\n",
    "'''\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "'''\n",
    "Teilmengen aus Trainingsdatensatz generieren\n",
    "\n",
    "'''\n",
    "\n",
    "#Trainingsmenge mit 50.000 Bilder erzeugen\n",
    "X_train_50000, X_test_10000, y_train_50000, y_test_10000 = train_test_split(X_train, y_train, random_state = 0, test_size=1/6, stratify=y_train)\n",
    "\n",
    "#Trainingsmenge mit 40.000 Bilder erzeugen\n",
    "X_train_40000, X_test_10000_b, y_train_40000, y_test_10000_b = train_test_split(X_train_50000, y_train_50000, random_state = 0, test_size=1/5, stratify=y_train_50000)\n",
    "\n",
    "#Trainingsmenge mit 30.000 Bilder erzeugen\n",
    "X_train_30000, X_test_10000_c, y_train_30000, y_test_10000_c = train_test_split(X_train_40000, y_train_40000, random_state = 0, test_size=1/4, stratify=y_train_40000)\n",
    "\n",
    "#Trainingsmenge mit 20.000 Bilder erzeugen\n",
    "X_train_20000, X_test_10000_d, y_train_20000, y_test_10000_d = train_test_split(X_train_30000, y_train_30000, random_state = 0, test_size=1/3, stratify=y_train_30000)\n",
    "\n",
    "#Trainingsmenge mit 10.000 Bilder erzeugen\n",
    "X_train_10000, X_test_10000_e, y_train_10000, y_test_10000_e = train_test_split(X_train_20000, y_train_20000, random_state = 0, test_size=1/2, stratify=y_train_20000)\n",
    "\n",
    "#Trainingsmenge mit 5.000 Bilder erzeugen\n",
    "X_train_5000, X_test_5000, y_train_5000, y_test_5000 = train_test_split(X_train_10000, y_train_10000, random_state = 0, test_size=1/2, stratify=y_train_10000)\n",
    "\n",
    "#Trainingsmenge mit 2.000 Bilder erzeugen\n",
    "X_train_2000, X_test_3000, y_train_2000, y_test_3000 = train_test_split(X_train_5000, y_train_5000, random_state = 0, test_size=3/5, stratify=y_train_5000)\n",
    "\n",
    "#Trainingsmenge mit 1.000 Bilder erzeugen\n",
    "X_train_1000, X_test_1000, y_train_1000, y_test_1000 = train_test_split(X_train_2000, y_train_2000, random_state = 0, test_size=1/2, stratify=y_train_2000)\n",
    "\n",
    "#Trainingsmenge mit 500 Bilder erzeugen\n",
    "X_train_500, X_test_500, y_train_500, y_test_500 = train_test_split(X_train_1000, y_train_1000, random_state = 0, test_size=1/2, stratify=y_train_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "speichert trainierte Modelle als Pickle-Datei.\n",
    "Diese gespeicherten Modelle können mit Funktion   load_trained_model_from_pkl(name)\n",
    "'''\n",
    "\n",
    "def save_trained_model_as_pkl(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pkl.dump(model, file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lädt bereits trainiertes, als Pickle-Datei gespeichertes Modell\n",
    "'''\n",
    "def load_trained_model_from_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        new_model=pkl.load(file)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Erstellt eine nicht normalisierte Konfusionsmatrix \n",
    "'''\n",
    "\n",
    "def plot_confusion_matrix(model, X_test, y_test):\n",
    "    #y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    normalize=False\n",
    "    cmap = plt.cm.Blues\n",
    "    #cmap = plt.cm.OrRd\n",
    "    #cmap = plt.cm.YlGn\n",
    "    #cmap = plt.cm.Greens\n",
    "    classes = ['T-shirt', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle-boot']\n",
    "    \n",
    "    title = 'confusion matrix'    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "          yticks=np.arange(cm.shape[0]),\n",
    "          xticklabels=classes, yticklabels=classes,\n",
    "          title=title,\n",
    "          ylabel = 'true classes',\n",
    "          xlabel = 'predicted classes')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_norm(model, X_test, y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    classes = ['T-shirt', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle-boot']\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    np.set_printoptions(precision=3)\n",
    "    \n",
    "    plt.figure(figsize=(4.5*2, 2.5*2))\n",
    "    \n",
    "    normalize=True\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 1.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            \n",
    "    #for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEYCAYAAADPkTRJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXdcVfUbx98P4N4DBcWBC1RcDFHce6Rp7q25yjQtKyttuLWflZlpu7TlLveeOYJwr3Jr4MYtSMDl+/vjHPCKlzvgKmjn/XqdF2d8v899zrnw8F3n84hSCgMDAwODB3HJaAcMDAwMMiNGcDQwMDCwgBEcDQwMDCxgBEcDAwMDCxjB0cDAwMACRnA0MDAwsIARHA3SjWh8LyI3ROTPdNipJyLHnOlbRiEiJUXkroi4ZrQvBmlDjHWOBulFROoB8wAfpVR0RvvzqBGRs8BApdTGjPbF4NFhtBwNnEEp4Ox/ITDag4i4ZbQPBunHCI7/MUSkhIj8KiJXReSaiHymn3cRkXdE5JyIXBGRH0Qkn36ttIgoEekrIv+ISJSIjNGvDQC+AWrr3chxItJPRHak+FwlIuX0/dYiclRE7ojIeRF5XT/fUEQizepUFJGtInJTRI6IyLNm1+aIyCwRWaXbCRORsqncc5L/z4tIhN79f1FEgkTkoG7/M7PyZUVks/58okTkZxHJr1/7ESgJrNDvd5SZ/QEi8g+w2eycm4gUFJFIEWmr28gtIidFpE+6v1CDR4dSytj+IxvgChwApgO5gOxAXf1af+AkUAbIDfwK/KhfKw0o4GsgB1AN+BeoqF/vB+ww+5wHjvVzCiin718E6un7BQB/fb8hEKnvZ9H9GQ1kBRoDd9C67gBzgOtATcAN+BmYn8p9J/n/hX7PzYFYYClQBCgOXAEa6OXLAc2AbIA78DvwiZm9s0BTC/Z/0J9rDrNzbnqZ5sAl/fO+BhZn9O+DsVnfjJbjf4uaQDHgDaVUtFIqVimV1MLrCXyslDqtlLoLvA10S9FFHKeUuqeUOoAWZKul0Y94oJKI5FVK3VBK7bVQphZakJ6qlIpTSm0GVgLdzcr8qpT6UymVgBYcq9v43An6Pa8HooF5SqkrSqnzwHagBoBS6qRSaoNS6l+l1FXgY6CBHfc1Vn+u91Je0D9zEbAJeAZ4wQ57BhmIERz/W5QAzunBJCXFgHNmx+fQWmRFzc5dMtuPQQteaaEj0Bo4JyLbRKR2Kv5EKKUSU/hUPB3+XDbbv2fhODeAiBQRkfl6l/828BNQ2IZtgAgb178C/IDvlVLX7LBnkIEYwfG/RQRQMpUJgwtoEytJlAQSeDCA2Es0kDPpQEQ8zC8qpcKVUu3QuphLgYWp+FNCRMx/R0sC59Pgj6NMQesSV1VK5QV6AWJ2PbUlHqku/dCX9HyJ1vUekjT+apB5MYLjf4s/0cb7popILhHJLiJ19GvzgFdFxFtEcgOTgQWptDJtcQCoLCLVRSQ7MDbpgohkFZGeIpJPKRUP3AZMFmyEoQXZUSKSRUQaAm2B+Wnwx1HyAHeBmyJSHHgjxfXLaGOzjjBa/9kf+BD4wVgDmbkxguN/CKWUCS3AlAP+ASKBrvrl74Af0SYfzqBNWLycxs85DowHNgIngB0pivQGzupd1hfRWmYpbcQBzwKtgChgNtBHKfV3WnxykHGAP3ALWIU2OWXOFOAdfZb7dVvGRCQAGInmvwn4AK2V+ZZTvTZwKsYicAMDAwMLGC1HAwMDAwsYwdHAwMDAAkZwNDAwMLCAERwNDAwMLGC8IO8k3HLmU1nyFbVd0AaViuV1gjcaJidNtjlzzs7VRWwXsgPnWNH4NyHRdiE7yObmvLZGopOeuZMeN+fOnSUqKsppj901bymlEh56kegB1L2r65RSLZ31mY5iBEcnkSVfUUr3m5luOzsntHCCNxox/6ZlieLDOCt4AOTO5pxfuSxODETnomKcYqdU4Zy2C9nJv/GWln46TrYszllKWSc40Cl2klAJ98jm08Vqmdj9s+x5K+mRYQRHAwODx48IuGTuNfBGcDQwMMgYJHNPeRjB0cDAIAPI/C3HzB26nzDyZHfjkx7VWPVqHVa+WofqJfMB0LN2SVaPrMuKV+rwessKAGRxFSZ19GPZiBB+Gx5CkHcBm/ZjY2OpW7smNf2r4V+tMhPGve+wjyaTiYYhgXTv1A6AZ5o1pEHtABrUDqBSuZL06tbRpo2TJ47RtG5Q8lahRGG+nv0pRw4dpG2z+jQO8adP1+e4c/u2VTuRERE806IJgdUrU9O/CrM/+xSACePeo3ZQdeoE+9OuTQsuXrjg0D1GRETQomkjqlepiH+1ynz26Qyr5Ue/+iIhfqVo2/DhcbVvP/8EX89c3LgWBcCKJfN5tnFNnm1ck25tG/P3kYN2+fTCwP6ULFaEgOp+Dt0LaN9743q1qBPsT62AqkyeMBaAQc/3JrBaJWoHVmPoCwOJj493yK6jz8npiFjfMpgn6vVBESmEpocH4IEmWHBVP66pv4+bWt2GwOtKqTYWrn2DpmV41MK1V4CvlFJWR+1zeFZQ81ZtYc+ZGyzefZ4srkL2LK5ULJaXFxuV4YU5e4g3KQrmysr16Dh61CpB5eL5GLPkMAVzZeWr5/3pPCuUveNTn5BRShEdHU3u3LmJj4+ncYO6fPjxDIJr1bJY3tKEzOyZ09m/dy937txm3uJlD1zr26MLrdq0pVuP3g+ctzYhYzKZ8K/ozaqN2xnUtzvvTZhK7br1mffjHCLOnWXUO2MfKG8+IXPp4kUuXbpI9Rr+3Llzh/ohQcxb+CvFinuRN682a//5rJkc+/son8z8/AE71iZkLl68yKWLF6nhr9kNCQ5g4eKlVKxUyWL5xSvWkzNXLt4aPogVW3fft3M+kndee4kzJ4+zZN0OChQqzN7wUMqW9yFf/gL8vmkdn300mYWrtwHWJ2R2bP+dXLlyM7B/H/bsP5xquSTMJ2RSfu8tm9Rn6ofTuXH9Os1atAJgYL9ehNSpx4DBLz5gx9qEjCPPqU5wIHv27HZaxHLJ7aGy+fW1WiY27H97lFLOnQlygCeq5aiUuqaUqq6Uqo6m6jw96dhaYLTD7sBUAqMr8Apm8lupkSd3LgJLF2Dxbk1RK96kuBObQLfgEny99TTxJu2f0PVozc2yRXITeupa8rnb9xLwK57P6meICLlza5KF8fHxJMTHIw78hz1/PpL1a9fQq2//h67duXOH7b9voXWbdnbbA9i+bTOlvMvgVbIUp04ep1adegDUb9SEVSt+s1rXw9OT6jX8AciTJw8+vr5cuHA+OTACxMREO3SPAJ6entTwv2/X17ciFy6krnQWVLsu+QoUfOj8lPff5I13Jz7QivEPqkW+/Forv1pATS5dtE9BrW69+hQs+PBn2EPK7z0+PgFBaN6yNSKCiOAfGMSF85E2LD2Io8/JuejdamtbBvNEBUd7EZEGIrJf3/aJSB79Um4RWSwif+t5QUQvv1VEAvX9uyIyXkTCgDFooqtbRGSLtc/0LlWS69HxTO7kx5KXazOhQ2VyZHGldOGcBHgXYP5LwfwwKAg/L+0P/++Ld2hcqQiuLkLxAjmoXDwvHvmy27w3k8lEcEB1ShYrQuOmzagZHGz3cxkz6jXGTpyCi8vDX/uqFUup36DxA4HJHpYtWUT7jtqSDJ+KlVm3egUAK5cuceiP9dy5sxzcv5/AIO1+xr//DhXLlWLh/F8Y8+44h3x6wO7Zs+zfv4+gmvY/J4DN61ZR1MMT38pVUy2zeN5c6jdunmbfHMFkMlE3OIDypTxp1KQJgWb3Ex8fz4JffqZJ87QvA0vrc0oXmbxb/VQGR+B1YKjewqyHpvIMmgz+K0AlND2+Ohbq5gIOK6WClVLj0URXGymlGln7QDc3VyoVy8P8sAg6zvyDmDgTgxp64+Yi5M2RhW6zw5i25jjTu2uZBX7dc57Lt2JZNLQWb7fxZf8/NzEl2l5P6OrqStie/Zw8G8nu8D85cth2Fw1g3ZpVFHZ3p3qNAIvXf120gA6du1q8lhpxcXGsX7OStu21ccqPP/uSOd98QYsGtbh79y5Zs2S1y87du3fp3b0zU6d9nByc3xs3kb9OnqNLtx58+cUsh/wyt9u9S0emffSJQ0H/XkwMX8z4H8NHvZtqmdCd21jyyw+8NmZCmnxzFFdXV3aE7eHIiXPs2R3O0SP3v/fXRgwjpG49QvRWu6Ok9TmlD9Fmq61tGUzGe/Bo2Al8LCLDgfxmgq1/KqUiden9/WhJkFJiApbY8yEiMlhEdovI7nOnjnP59r8cjLgFwPrDl6hULC+Xbv/LhsOamPahyFskKiiQKwumRMXUVcfoMPMPhv24jzzZ3Th3zf7FyPnz56d+g4asX7/WrvJhobtYu3ol1SuVY1C/nmzftoUXBmjJ765fu8bePeE0b9na7s8H2LxhLVWqVce9iPZmUPkKvsz/bTXrtoXSvlMXSnnb1oONj4+nV/dOdOnag2fbd3joeucu3Vm+NKWcom3i4+Pp3qUjXbv3pP1zD9u1xj/nThP5z1naNalF46CKXL54ng7N63D1ipaV4djRQ7z72lBmzVlAgYKFHPYtPeTPn5+69RqwacM6AKZOGk9U1FUmf/Bhmuyl5zmlC8HoVj8ORGSoWTe6mFJqKjAQLQtcqIj46kX/NatmwvJSplhdkNQmSqmvlFKBSqnAa3fjuHgzltL6oHytsoU4eeUum45cplZZ7Q+odOGcZHEVbkTHkz2LCzn0wfKQcoUwJSpOXbGe9vnq1avcvHkTgHv37rF500Z8fHyt1knivXGTOHz8LPuPnuTrOT9Tr0Ejvvz2BwCW/baY5i1bkz277W69OUuXLKR9x/utzairVwBITExkxrSp9H5+kNX6SimGvjgQH5+KDBvxavL5kydPJO+vXrWCChV8HPJLKcWLgwbg41uREa+OdKgugE9FP3YdPsfm8L/YHP4XRT2L8+v6nbgX8eBCZAQvD+jBBzO/wbtseYdtp4WoFN/7ti2bKF/Bhx++/5bNG9fz7dyfLQ6V2CK9zyl9ZP6W41OxzlEpNQtI7nuJSFml1CHgkJ68yRe4mUbzd9Bk86NsFZy04i+mda1KFlcXIq7HMGbxYe7Fm5jY0Y/lI0KINyneXqR1hwrmyso3/QNJVIort//lzYWHbDpy6eJFBvXvi8lkIlEl0rFTF1o/89Dku8P8tnghI14b5VCdmJgYtm/ZxP+m3+/yLl28gDnffAFAq7bt6dbL+mxk6K6dzP/lJyr7VaFOsDYx8N64ifw45ztOnDiOi4sLJUqW5JNPP7dqJyW7du7kl59/xM+vCsEBWkLCcRMn07KV5ZbxyCF9Cd+1nRvXr9HAvzwvv/4OnXpY9n329CncvHGd8W+/AoCrqxtL1qUUOn+YPr26s33bVqKioihb2ot33xtHv/4D7LqfS5cuMmRQf0yJJlRiIu07dKJl6zYUypONEiVL0axhXQDatmvPm6NTHwpIiaPPyakI4JrxrUNrPFFLecwRkbHAXaXUQ/0JEZkJNEJrHR5Fy6NcG7OlPHoS991KqTkislW/tltE7iqlcpvZehkYCly0Nu6Yw7OCcsa71fuMd6vtwni32j6c+W61U5fy5C2usgUNtVomdvOYDF3K88S2HJVSY61cs5T7ZKu+JZUZZrbf0Gz/gfSeSqmZQPqjnoGBgRmSKbrO1nhig6OBgcETTiaYdLGGERwNDAweP5lkLaM1jOBoYGCQMRgtx/8GFYvlZef49L8tUSBomO1CdnL9z8w3VOrmmvlaCyUK5shoFx7CWRMpmRdjzNHAwMDAMka32sDAwCAFIuCSucNP5vbOwMDg6cVoORoYGBhYIJNPyGTuEVEDA4OnE0n/u9Ui8qqIHBGRwyIyT0Syi4i3iISJyAkRWSAiWfWy2fTjk/r10rbsG8HxMWEymagV5E+H9m3tKj+0e0N2LxrNnsVjGNajIQCTX2nP/l/f4c8Fb7Pgo0Hky63NsmZxc+XLsb0IXziasAVvUS/APkGEmzdv0qNrZ6r7VaRGlUqEhf7h8D2Zp1xI4s3XRlCyaH6HbAEcP3aM4MAayVvRQvn47NNPHLYDsH7dWqpW9qGybzmm/W9qmmwAzJwxncDqfgTWqELf3j2IjY1Nsy1n+ZSelAuPwk6aSYeeo4gUB4YDgUopP8AV6AZ8gCaCXR64ASS9wD4AuKGUKgdM18tZJcODo4gUMlPUuSQi582O7RMEfAKYNXMGvr4V7Spbqawnz3cIoV7vadTsOoVW9f0oW9KdTaF/E9B5MjW7TuHEuSu80V9bOtS/gyZLGdRlMm1e/IypI5+zSz37jZGv0KxFC/Yf/ouwPfvxsdO/JL6c/SkVfB6ss2/vbm7dSpvGRwUfH8J27yNs9z52he0mR86cPNvuOYftmEwmXhk+lGUr1rDv4FEWzZ/HX0cfEnq3yYXz5/l81ky2/xHO7n2HSDSZWLRwvsN2nOkTQO++/Vi20j6pusdhJy0I4OLiYnWzAzcgh4i4oan1XwQaA4v163OB9vp+O/0Y/XoTsfFHkuHB0Z7UB6Lx2HzVH7bTiIyMZO2a1XarsPh6e/DnobPci43HZEpk+56TtGtUjU2hf2MyaSIQfx46Q3G9deZbxoMtfx4D4OqNu9y6c4+ASiWtfsbt27fZseN3+j2v+ZQ1a1by57e/tWcp5YLJZGLsmLcYOzHtraIktmzeRJkyZSlZqpTDdcP//JOyZcvhXaYMWbNmpXPXbqxcscx2RQskmBK4d+8eCQkJxMTE4OlZLE12nOlTelIuPAo7aULs2KBwkl6qvg1Oqq6UOg98CPyDFhRvAXuAm2b6rZFAcX2/OBCh103Qy1sV48zw4JgaIlJOH0v4AtgLeIpILxE5pJ+frJdzE5GbZvW66QmzkvYPi8iBpDQHevmPReRPETkoIgP1801FZKOIzAf2iUgeEVmj1z0sIp3Sei+jXnuViVM+sFtz78ipC9T1L0fBfLnIkT0LLetWxsvjweyEfdrVZt1OreVx6Ph52jasgqurC6WKFaJGpRIPlU/JmdOnKVzYnRcG9qdWkD9DXhhIdLR1PUlzLKVc+OaLWbR8pg0eHp5220mNRQvn07lrtzTVvXDhPF5eJZKPixf34vx5x3OjFCtenBGvvIZvuVKULVWMvPny0bRZ2hb6O8unpwdJzn+T2gZEJeml6ttXybVFCqC1Br3RUpnkAlpZ+KAk2TFLrUSrkmSZNjjqVAK+VUrVQLu5iWhSZDWAOiJiS8zwfaCJUqoakNQ/GwxcUUrVBIKAoSKS1MyqBYxSSlUBWgNnlVLV9DGNDSmNmyuBR0VdTXkZgNWrVuJexB1/f8vpCSxx7MxlPpqzgZWfD2P5rKEcPH6ehIT7ElajBrTAZEpk/upwAOYu+4Pzl2+y8+dRTHujI6EHzpBgsi55lWBKYP++vQx84UVCw/eSK1cuPrRzHMxSyoWLFy+wbOkSBr2Y/jd84uLiWL1yBR06dk5TfUsyfI4m6QK4ceMGK1cu58ix05w8e56Y6Gjm/fJThvr0NJHObnVT4IxS6qpSKh74FQgB8pv1/LzQ0pyA1oosAck9w3zAdav+pe22HhunlFLh+n4wsFkpFaU/jF+A+jbq7wR+0FuHSffaHHheRPYDYUB+IGkG4w+l1D/6/kGgpYhMFZE6SqlbKY2bK4EXLuxu0YHQXTtZtXIFvuW96dOrO9u2bKZ/394Wy5ozd+kfhPT4gGYDPuHGrWhO/qMF355tg2ld349+Y+YklzWZEhn10a/U6jaVLq9+Rf48OZLLp0bx4l4U9/Kipp5Q6bkOndi/f59Nv8ByyoU6QdU4c+oUgVV9qV6pHDExMQRWtU+lPCXr1q6heg1/ihYtmqb6xYt7ERkZkXx8/nwkxYo53h3esnkjpUuXxt3dnSxZsvBs++cI+2NXhvr0NGFHy9Ea/wC1RCSnPnbYBE27dQuQ1MvrCySNXSzXj9Gvb1Y2xGwze3A07+el9rQSU1wz1/ofhNZ6LA0c0JviArxkNq7prZRKyoWd/HlKqb+AQOAIME1ERqflBsZPmsLJMxH8feIMP/w0jwaNGvPd3B9t1nMvoMlKlvAoQLvG1Vi4djfNQiryWr+mdHrlS+7F3k/gniN7FnJm1+auGgf7kmBK5O/Tl6za9/DwwMurBMePaWOVWzZvomJF+yZkLKVcOB15lb9OR7L/6En2Hz1Jzpw52X3wb7vspWTRgrR3qQECg4I4efIEZ8+cIS4ujkUL5vNMm2cdtlOiREnCw8KIiYlBKcXWLZsdnrRytk9PCyKCuFjfrKGUCkObWNkLHEKLZV8BbwIjReQk2pjit3qVb4FC+vmRwFu2fHySFoGHogWpQmiDqd2AD5VSiSJyQ0TKA6fQus9JzaYySqlQPc3qs2iDsuuAl0Rkm1IqQUR80P4LPYC+VCBKKfWjiNzTP++xMe/DgRTMn4v4BBOvTF3IzTv3mP5mF7JldWPl51rX9c9DZxk+aT7uBfKwYvZQEhMVF67eZMA7c21Y1/ho+qc837cX8XFxlPYuw5fffPcob8kuYmJi2LxpAzNnf5FmG25ubkyf8Rltn2mByWSib7/+VKpc2WE7QTWDad+hI3WCA3B1c6Na9Rr0HzjYdsVH6BOkL+XCo7CTVtI7rKCUeh+t8WPOaaCmhbKxgEPjNJkqTYJ56gMRKQcs1mexk673Bkahtf5WKKXe1s93BSajBbmjQDal1EARWY42YCvAeqXUSBFxBSYBSeOVV9AGdoOBYUqp9rrN1sBUtJZpHPCiUmpvar77BwSqnaHhqV22m4I1LYmYpw1nqfLci3OOZD9AjqzOeSvCmeN1iYnO+RtwsdHaeZJxdpoEt0JlVN7WE62WufFTTyNNQhLmqQ+UUieB6imu/wg81CdVSi0AFlg4/1C/Rc8s+BYPN6s36ltSudXAaoduwMDAwD4Em13njCZTBUcDA4P/Dpl9tt4IjgYGBo8dQdKUa/txYgRHAwODjCFzNxyN4JjZcGZqgxrvrneKnX0T0p/+IYnDEbedYqdKyXxOsQNw+1687UJ2kD+X86QAEkzOyRXu5ppJW2didKsNDAwMLGJ0qw0MDAxSINj1FkyGYgRHAwODx4+xlMfAwMDAMpm95Zi5O/1PCc5UuHZUvTtPdjdm9KzG6pF1WDWyDtVL5uPj7lX5bXhtfhtem01v1ue34bUBqOKVL/n80hEhNK1cxG6/7FU6v3whkiE92tCleU26tqzF/O8/B2Dj6qV0bVmL4HIFOHrwYQGMSxciaFClOD99bd+EVVpVt0+eOEbTukHJW/kShflq9qcAfPvlLOoG+tGgVnUmvPe23TbT69OQwQPwLuFBTf+qyecOHTxA4wZ1CA6oRucOz3L7tuMTXRmtBJ5O4YlHTqZrOYqICe1FcjfgL6CvUirGSvk5wEql1GIR2Qq8rpTa/Th8tZckhWvQgkjZ0l5pUriG++rdvyxYRFxcHDExqT4aAMa09WX78ShG/HyALK5C9iyujJx3MPn6m8/4cCdW0wY9cfkOnT4LxZSocM+TlaUjQtjyl3V1nySSlM5v37H+R+rq5saI0RPx9atO9N079GnXkJp1G1G2QkX+N/tHprzzisV60yeOpnaDpnb5kqS6vWrNBop7eVG3VhBt2jxLxUqVbNYtV96HjTvCk+3UqOhNqzbt2Pn7VtatXsGmnXvIli0bUVev2OWLM3zq2bsvLwwZyuAB/ZLPDRsymElT/kfd+g34Yc53zPj4Q94dO94hn3r37ceLLw1jYP8+DtVzFpm9W50ZW473dLUcP/R3mjPaoST097LTRXoUrh1V786VzZVA7wIsDtdEVeNNKjkQJtGySlFW7b8IQGx8Iib9PeOsbq7Y+9q9I0rnhYt44OunvRWaK3cevMtV4Orli3iX86FUGcu5b7auX0nxEqUpU94+CTRnqW5v37aZ0t5lKFGyFHO/+4phr75BtmzZtPtwt79VnV6f6tarT4ECDyp2nzh+jDr1NMW+xk2asWzprw75k2Q3o5TAbbUaM0PLMTMGR3O2A+VEpLSIHE46KSKv6yIVqSIi3c1Uwz/Qzw0Rkf+ZleknIjP1/V66Ovh+EfkyKRCKyF0RGa8r+9RO7w2lR+HaUfXuEgVzcj06nimd/fh1eG0mdKxMjiz343ugdwGu3Y3j3LX7rc+qJfKx4tU6LH8lhLFLjyYHS2s4qnSexIXIcxw7cojK1VIXAr4XE80PX81g4PA37bfrJNXtZUsW0b5jFwBOnzxB2K6dtG5Sl+daN2X/Xsc6J85WAq9Y2Y9VK5cD8NuvizlvphX5pGAExzSiq/W2QutiO1q3GFp2scZo4hVBItIeTf+tg1nRrsACEamo79fRVYBMQE+9TC7gsFIqWCm1I8Xn2FQCNye9CteOqne7uQiViuVhXmgEHT79g3txJgY19E6+/kw1D1YduPhAnYMRt2g7fSedPwtlcMMyZHWz/iuSFqVzgJjou7z1Uh9GvjuZ3Hnyplruq0+m0P35l8iZK7fdtp2huh0XF8e6NStp274joD37WzdvsGrjdt6bMIXB/XpY/JxH6ZM5s7/8hq+/mE292kHcvXOHLFmfvFx06dFzfBxkujFHtGxi+/X97WgilY5KJgcBW5VSVwFE5GegvlJqqYicFpFawAnAB00tfCgQAITrv7A50KTMQAuUSyx9iJ7T4ivQJMtsOeUMheuU6t0fTks9w+SlW7Fcvv0vByM0EfN1hy4xqGEZAFxdhGaVi9JxpuUJndNXo7kXZ6JCUetBKUnpfN3aNcTGxnLn9m369+1tVdA3IT6eN4f2oUW7zjRqYV3w9fCBPWxeu4zPPniPO7dv4eLiQtZs2ajyzhup1nGG6vbmDWupUq067kW078qzWHFat22PiFAjIAgXFxeuXYsiNQX4R+GTOT4+vixbtQ6AEyeOs27tkycglRlah9bIjMHxnrmGI4CIJPBgKzc71rH21BcAXYC/gd+UUkqXWZ+bpA+Zglhd5izdpFfh2ly9u4KPj0317qi7cVy8GYt34ZyciYqhdrlCnLp8F4Da5Qpx5mo0l2//m1y+eIEcXLoViylRUSx/drzdcxJ5455Vn8ZPmsL4SVMA+H3bVj5Th5I/AAAgAElEQVSZ/pHVwKiUYsJbw/AuW4GeA2znm/l6wZrk/a9mTCFnztx06WNdcNZcdbtY8eIsWjCfOT/+YvOzzFm6ZCHPdeyafNzymWfZ8ftWQuo14NTJ48THx1OoUGG77TnDJ3OuXrmCe5EiJCYmMm3KpDSL8GYUIplf/zIzBkdLXAaK6Crgd9GEaq0l3A0DZohIYbTE3t2BpDUgvwJjgHNokuoAm4BlIjJdKXVFRAoCeZRS55x1A85QuAbH1bsnLv+Lad2qksXVhYjrMYxerA3dPlPNg5UputQBpfMzqGEZEkyJJCoYt/QvbsY4573jJA7sCWXN0gWU86lEzzZ1AXjptfeIi/uXj8a/yY3rUYwc2IXylaowc47jkwyQftXtmJgYft+yif9Nn5V8rnuvfrw6bDANa9cgS5aszJj9jUMtn/T49HzvHmzfvo1rUVH4lC3J6HfeJzo6mq++mA3As+2fo3ff5+32JYmMVQLPHOOK1shUSuCgTYAopR7qy4nIcGA4cAY4j5YZcGxqS3lEpAfwNlorcrVSapSZrZVAJaVUGbNzXfXyLkA8MFRPsWDRn5Q4SwncmRjCE/ZxMzrOKXaeZuEJZyuBZ/eooEr2+dRqmRPTWhlK4OakFoiUUp8CDz1NpVQ/s/2GZvu/oGUotGTroZSuVtTE7Z8JMDAwsA+jW21gYGDwMIIRHA0MDAwsYgRHAwMDg5SINmOdmTGCo5NQCuIS0j+I7kzl5j/es+9dZFsU7ZP60hxHOfVVd6fZchZZMqFatktmjxzpRDDWORoYGBhYQIxutYGBgYEljJajgYGBQQqMN2QMDAwMUiGTNxyN4GhgYJAxZPZudeabpntKiI2NpXG9WtQJ9qdWQFUmTxgLwKDnexNYrRK1A6sx9IWBxMdbf3d5yOD+lPYqSlCNKg9dm/Hxh+TO5kJUVJTdfplMJhrUDqRbR00N5+Uhg6gX7E/dmjXo27MLd+/etVivnGdedkxpk7xFftuNl1pVpEqpAmwa34odU9qwdVJrAsoWeqCef5lC3Pi5F+1qlrRo99bNm/Tv3ZWQAD/qBFYhPCyUG9ev06ldK4KrV6JTu1bcvHHD7vsDiIiIoEXTRlSvUhH/apX57NMZDtWvUbkc9YKr0zAkgCb1NQWkKRPep36tGjQMCaBTu1ZcvHjhsfn04uD+lPIqSqDZ78D169dp06o5VStVoE2r5txw8BklkdbUDelG71Zb2zKaJzo4iohJF6c9IiIHRGSkiGSKe8qWLRvL12xkZ9hetofuYdOGdYT/GUrnrt0J33+EXeH7iY29xw/ff2vVTs/e/Vi6Ys1D5yMjIti8aSMlSloOOqnxxaxPqeBzX1F70gcfsT1sLzv+3IeXVwm++WKWxXonL96m7tsrqfv2SuqPXsW9OBMrwv9hQo8Api45QN23VzJ50QHG97iv6+giwrge/mw6kHogGfPmSBo3bcGuPYfZsmsPFXx8+XT6/6jfoBFh+49Sv0EjPp3+v1TrW8LNzY2p//uI/Yf+YtuOUL78YhZ/HT3qkI2lqzayddceNv0eBsCwEa/xe+g+tu7aQ/OWrflw6sTH5lMvC78DH02bSsPGjTl49DgNGzfmo2mOB7ak1A3LVqxh38GjLJo/z+HnlFa0pTzWN7vsiOQXkcUi8reI/CUitUWkoIhsEJET+s8CelkRkU9F5KSIHBQRf2u2M0UgSQdJKRUqA82A1sD7KQvpwrmPFREhd27ttez4+Hji4xMQhOYtWycrHfsHBnHhfKRVO5Yk8gHefGMkE6d84FDX5Pz5SDasXU3vfv2Tz+XNqwnNKqWIjY21y15DPw/OXL5DRFQ0SkGeHJrgQt6cWbhkJnH2Yktflof9w9XbsRbt3Ll9m9BdO+jZR1OUyZo1K/ny52ftqhV07dEbgK49erNGV7y2F09PT2r4a7/3efLkwde3IhcupF11GyBP3vuCvDHRMQ53CdPjU9169SmY4ndg1Yrl9OzVF4CevfqycrnjaSCclU4ibTgtTcIMYK1SyheohpZ36i1gk1KqPJri1lt62VZAeX0bDHxuzbDN4CgiZUUkm77fUESGi0jqiUsyCKXUFbQbHqb/h+gnIotEZAWwHkBE3hCRcP2/xjj9XC4RWaW3PA/r6jyIyFQROaqX/TAtPplMJuoGB1C+lCeNmjQhUBepBS1gLvjlZ5o0b+Gw3VUrllOsWDGqVK3mUL3Ro0YydtLUh9IZDH1hAL7exTlx/G8GDbGtsdgxxJvFu84A8OYP4UzoGcDRzzoysWcgY+fvBcCzQA7aBJXg243HU7Vz9uxpChUqzPAhA2lcN4hXh71AdHQ0V69eoaiHJwBFPTyxR2U9Nc6dPcv+/fsIMnv2thAROrVvReN6NZn73dfJ5yeNe5eqvt4sXjiPt8aMfaw+peTKlct4emrPyNPTk6sOJvwC56ducJT0dqtFJC9QH00QG6VUnFLqJtAOmKsXmwu01/fbAT8ojVAgv4h4puqfHfewBDCJSDndCW9SUbvJaJRSp9HuKSn7UW207IWNRaQ52n+MmmipEwJEpD7QEriglKqmJ/Vaq+s5PgdUVkpVBSz2oczTJFyz8Afs6urKjrA9HDlxjj27wzl6JDkNDq+NGEZI3XqE1Knn0D3GxMQw7YPJvPO+Y5nm1q1Zibt7EarXeDidwawvv+XoqQgq+FTkt8ULrdrJ4upC6wAvfgvTpC4HNqvA2z+GU2nYEt7+MZzPBocAMLVPEO//spdEK5J4pgQTBw/so9+AF9i8I5ycOXMx82PHutDWuHv3Lt27dGTaR58kt5DtYdWGbWzZEc6CX1fy3defs2vHdgDGvD+Bg3+foVOX7nzz1ezH6tOjwNmpGxzCRpfaTjfKAFeB70Vkn4h8IyK5gKJKqYsA+s+keFAcME+2E6mfs4g9wTFRKZWAFiw+UUq9CqQabTMB5o91g1Lqur7fXN/2AXsBX7RgeQhoKiIfiEg9pdQt4DYQC3wjIh0Ai/lPlVJfKaUClVKBhazI5efPn5+69RqwaYMmaz910niioq4y+QPHG6SnT5/i7Nkz1A6qTqUK3pyPjKRurQAuX7pktV7YH7tYs2oF1SqWZWDfnmzftoUXzFJyurq68lzHzqxYZl1gtln14hw4c52rt7Sucvf6ZVn+5z8A/BZ6LnlCpkaZQnw3vD6HPu1Au+BSfNw/mGcCSzxgy7N4cYoV9yIgqCYAbdt34OCB/bi7F+HyJU2I9/Kli3anIjAnPj6e7l060rV7T9o/18F2BXO/PLX0Be7uRWjdtj179zyo09mxSzdWLvvtsfqUkiJFinLxovaMLl68iLuD2RDB+akbHEFT5XGxugGFkxof+pZS7twN8Ac+V0rVAKK534VO7WNTkup/b3uCY7yIdAf6Aiv1c1nsqPfYEZEyaDlfkvoY5qn5BJiij1FWV0qVU0p9q5Q6jpY/5hAwRUTe0/8Z1ERrNbfHuuq4RaKuXuXmzZsA3Lt3j21bNlG+gg8/fP8tmzeu59u5PzucrQ/Az68KZyMvc/T4GY4eP0NxLy92hO6hqIeH1XrvjZ/MkRPnOPDXKb6Z+zP1GjTii2/ncvrUSUBrRaxdvZLyFXys2ukcUppFepca4NKNGOpW1PKsNKjswalLdwCoOuI3qgz/lSrDf2VZ2DlGfhfGqt0PZsgrWtSDYsW9OHniGAC/b91MBd+KtGjdlgW/aO9zL/jlR1o+09aBJ6Tdy4uDBuDjW5ERr450qG50dDR37txJ3t+6aQMVK1Xm1MkTyWXWrl5h8zk50ydLtG7Tlp9/0nqOP/80l2faWs/FYwnz1A1xcXEsWjCfZ9o4biet2NFyjEpqfOjbVylMRAKRSqkw/XgxWrC8nNRd1n9eMStv/h/aC0h1ttCeiYrn0XJHT1JKnRERb+AnO+o9VkTEHfgC+EzPC5OyyDpggoj8rJS6KyLF0RS/3YDrSqmfROQu0E9EcgM5lVKrRSQUOOmoP5cuXWTIoP6YEk2oxETad+hEy9ZtKJQnGyVKlqJZQy1FQNt27Xlz9Lup2unXuwfbf9/KtagoKpQpwZh3x9L3eedI2SuleGnw89y5fQelFH5VqvLhDMuz1QA5srrSqEoxRnwTmnzu5a9D+aBPEG6uwr/xJkZ8YzlhV2pMnjadIQP7EhcXR6nS3nw6+xsSExMZ1K8HP/8wB68SJfhm7jyHbO7auZNffv4RP78qBAdo6YjGTZxMy1atbda9euUyfXt0AiAhwUTHLt1o0qwF/Xp24eSJ47i4CF4lSvGRlefkbJ/6mv0OlC9TgnfeHctrb7xF7x5d+eH77/AqUZKf5lkfDrFEetNJpJf0duGVUpdEJEJEfJRSx4AmwFF96wtM1X8mzTItR5uTmA8EA7eSut8W/bMnTYKI5ABK6g5kGkTEhNbiywIkAD8CHyulEkWkHxColBpmVn4EMFA/vAv0AsoB04BEtGA5BC0NwzK0RF4CfKiUShrgtUgN/0C1dWeYtSJ24UxVHmeoBAGUGvCzU+yA81R58uRwXuclOjbBKXZyZXfeoohEO/KF24Oz1gs6O01C3pIVVeDr1vMfbRkRYjNNgohUB74BsgKn0RpzLsBCoCTwD9BZKXVdT6T3Gdo8QwzwvFIq1QTkNr9NEWkLfKh/uLfuzHil1ONrf6eCUsrVyrU5wJwU52agTf2bcwqtVZmSmul0z8DAwArOmPtRSu0HLAXQJhbKKrQ0zHZhTzNlLFqguGnmjLe1CgYGBga2cHURq1tGY08/IEEpdSvF+EDmSlloYGDwRKFNumR8ALSGPcHxsJ7m1FVEyqOlR931aN0yMDB42skEjUOr2BMcXwbGAP8C89BnfR+lU08iLgLZsqQ6BGo3zswjHnHN4vJMh/nnu55OsQNQd9Jmp9jZPbaZU+wA3M6EEzL/ha5ZZhCXsIbNb1MpFYMWHMeIiCuQSyll+WVZAwMDAzsQQCyuyc482PNu9S8ikld/LecIcExE3nj0rhkYGDy1iPXJmMwwIWPPbHUlpdRttDdFVqOtHer9SL0yMDB46nGGZNmjxJ7gmEVEsqAFx2VKqXj+G0MiBgYGjwhB0/u0tmU09gTHL4GzQC7gdxEphSbMYGAnLwzsT8liRQio7ucUeyaTiVpB/nRob/ud4/def4mGNcrQoel9eaw3XupHl5Z16NKyDq1C/OjSsg4A5yPOUbN8keRrE95+xaLN2NhYmtSrRd1gf2oHVGWKrnKexKiRI/Byz5eqT3myu/Fxt6osHxHC8uG1qVYiHy81LsOmUfVYPLQWi4fWol6FwgA8U80j+dziobU4OL4pPh65bd63IwrXo4a/QFDFkrSsd1+xaPWyJbSo60/ZIjk5uH/PA+X/OnKIjq0a0KKuPy3rB/JvrH1D8GlV3bakBj9+7LsEB1SjdlANnm3dgosXHFMmT69PzuCJVwJXSn2qlCqulGqt66CdAxo9Bt/ShYh4iMh8ETml6zKuFpEKDtrILyIvpdeX3n37sWylw9oVqTJr5gx8fSvaVbZd5558/sODSjvTZs9h4dqdLFy7kyatnqVxy/tB1quUd/K1d6d8YtFmtmzZWLZmIzvC9vK7mco5wL49u7l166ZVn956xoedJ67x7IxddJgVyumrmj7Ijzv/odOsUDrNCmX7cS31w6oDl5LPvb34MOdv3uPYJcupHJJwVOG6U7fefD//QZHXChUr8/mc+dSsXfeB8wkJCYx8qT8Tp81k3Y69zFu6Drcstl9lTI/qtiU1+FdGvkHYngP8Eb6Plq2fYcokxyTs0utTerHVpc4EDUe7JmRG6BMyIiLfisheoPFj8C3N6O9Q/gZsVUqVVUpVAkYDRR00lR9Id3CsW68+BQs+rOadFiIjI1m7ZjX9+tsnPhEQXIe8+QtYvKaUYv3K32jVrpNDPqSmcm4ymXhvzJuMm5h6CyRXNlcCShdgyR5NVDXBpLhj51Ka1lU9WHPQujQbOK5wXTOkLvlTKG2Xq+BLmXIP/y/dvmUjvpX8qOhXFYACBQvh6mp7CVd6VLctqcGba0HGxESnaUF1xiqBPx3d6v76hExzwB3txe7H2/52nEZAvFLqi6QT+muPO0Rkmq74fchM9Tu3iGwSkb36+XZ6talAWdHy1Ex7/LfxMKNee5WJUz5Ik9xZSvb+uYtChYtQyrtc8rnzEefo0qou/Tu3Ym9Y6mv9TSYT9YIDqFDKk4a6yvnXX8yi1TNt8fBMXe7Tq0AObkTHMbFDZRa9FMy49pXIkUW7l+61SvDrsFpMeK4SeS2sGWxZpSir7QiOj1Lh+sypE4gIfTu3pW3j2nw58yO76j0Kn8a+NwafsiVZMO8Xh8WPH5VPjvA0BMckL1sD3yulDpidy6z4AXssnO+ApgJeDWgKTNP13mKB55RS/miB9SO99fkWcErXf3xo+ZK5EvjVdEj528vqVStxL+KOv//Dat5pYc2yxbQ0azW6F/FgXegRFq7ZwevvTuat4QO4e8fy8LKrqyvbdZXzvbvD2bnjd5b+upjBNtIsuLm4UNEzDwv+jKDz7DDuxZkYUN+bBWGRtPp4Bx1nhXL1zr+80erBVlsVr7zcizNx8kp0Kpbv8ygVrk2mBHaH7WL6F9+zcOUm1q9ezs7ft2SIT2PHT+LYqX/o2r0HX37+mcP1M1IJXJuQsb5lNPYExz0ish4tOK4TkTxo8l5PInWBeUopk1LqMrANCEL7riaLyEFgI5p0us0uuLkSuHsa1KodJXTXTlatXIFveW/69OrOti2b6d83bauqEhIS2LR2OS3b3lekzpotG/kLaErelarWoEQpb86dti5lmU9XOd+xbStnTp3C38+Hqr5liYmJwd/vYUHYS7djuXz7Xw5FakF3/ZHLVCqWh2vRcSQqUAoW7z6Pn9eDEzqtqniw5pDtViM8WoVrj2LFCa5dj4KFCpMjZ04aNm3JkYP7MtSnLl17sOw36wruj9snm4j1yZgnYkIGGIDWggrS35bJita1zswcQVP3TklqT7wn2pBBgFKqOnAZTcsxUzF+0hROnong7xNn+OGneTRo1Jjv5v6YJlthO7bgXbYCRT3vp9C4fi0Kk8kEQOS5M5w7cwqvUqUfqht19Sq3zFTOt27ZRLUa/hw7e56Df5/i4N+nyJkzJ3sPPyz/ee1uHJduxVK6cE4AapUtyKkr0RTOnTW5TJNKRTh5+f6kiwg09yvKmoOX7bq3R6lwXb9RM/4+eph7MTEkJCQQtms75SrYnhxztk8nT9xXJl+1cvkD6XbtJeOVwJ2SffCRYc/rg4kicgaoICKZLmCkwma0luAgpdTXACISBNwAuorIXKAgWuayN4CuwBWlVLyINAJK6XbuAHnS60yfXt3Zvm0rUVFRlC3txbvvjbN7QiW9vDnseXb/sYObN67RrKYvQ0aOpkO3PqxdvoSWzz44EbM3bCezPpqEm5sbLq6uvDP5E/Llf3gi6dKli7ykq5wnJibynK5ybi+TV/7NB52rkMVViLh+j3d/PcLbbXzw8dAe9fkbsYxbdn/WNLB0AS7fjiXSLO2rNRxVuB4+uA9hO7dz43oUIVXLMmLUu+QvUIBxb4/k+rUoBvToQKXKVZm7aAX58hdgwJDhtG9eFxGhYdMWNG7eyuk+mWNJDX7d2jWcOH4MFxcXSpYsxYzPrGYZdbpP6SWpW52ZsakELiIDgRFo+Rb2A7WAP5RSmX3GuhjwCVoLMhZtreYraOlbW6EtZJ+olFogIoWBFWiK4vuBOkArpdRZEfkFqAqssTTumERAQKDaGZaqqLDdOFN44oSNJS/2UlJv5TmDzCg8cfGmc6QCPPM7r+1gcpISuLNew3O2EnjhMpXVs5PnWy3zffeqNpXAHyX2yIiMQBuXC1VKNRIRX2Dco3Ur/SilLgBdLFx6Q9/My0ahpXG1ZKeH870zMPhvI0KmmJG2hj3BMVYpFauPA2RTSv0tIo6lXjMwMDBIQWaYdLGGPcExUkTyA0uBDSJyAyvpDA0MDAzsIZM3HO2akHlO3x0rIluAfKQhj7OBgYFBEkLmWOhtjVSDo4hYet/tkP4zN3D9kXj0H8eZSxjKFbUt0GAPzvwddtZEikdf56VOP/+9c5TOL99ynga0e55sTrFzMzrOKXYSnDRBlIw82d3qPWgzuuZ3kHSsgDKP0C8DA4OnHOdlaH80pBoclVJG+lUDA4NHguC8ZUaPCntUeZ4TkXxmx/lFpP2jdcvAwOBp52l4t/p9pdStpAOl1E3g/UfnkoGBwdNOUt7qJ/r1QSwHUOfloDQwMPhP4prJBx3tCXK7ReRjYBbaRMzLWJYDM0iFiIgIBj7fh8uXL+Hi4kL/AYMZNnxEmmytX7eW10eOwGQy0a//QN4Y9Vaa/Zo5Yzpzv/8WRKjsV4Uvv/6O7NkdfwXOt7w3eXLnwcXVFTc3N3aGhjtsIy3PqJxnXr5/+b5Sd6kiuZmy+CBB5QtT3lMTg82XMyu3YuKoN3o1WVxd+GRAMNXLFEQlwls/7mbHXw+LWQwZ3J81q1fh7l6E8H2HHrg24+MPGfP2KM6ev0LhwoUfqvvG8BfYvH4NhQq7s36H9mdy88Z1hg3sTeQ/5/AqWYpZ3/5EvvwF+HLmxyxdsgAAU0ICJ4//zd5jEQ8J76Ykrd/byRPHePH5XsnH586d4Y233+P2rVv8/MN3FCqk3c/b742niR3vi6eHpBwymRl7YvfLQBywAFgI3AOGPkqnLCEiY0TkiIgc1MVng23Xsmlzq4hYfXfTnjK2cHNzY+r/PmL/ob/YtiOUL7+YlSY5emfK2l84f57PZ81k+x/h7N53iESTiUULrb/rao01GzYTtntfmgIjpO0Znbx4m3qjV1Nv9GoajFnDvX9NrNwdQf+ZO5LPLw//hxXhmixX38aaqG+dt1bRfupGJvb0t7hMyVJaAoDIiAg2b9pIiZIlU/WpU7fezF3woJr25zM+JKR+Q7aGHyakfkNmz/gQgBdeHsmarWGs2RrGqHfGExxSz2ZgTM/3Vq68Dxt3hLNxRzjrtoWSI0dOWrXRdJ0Hv/Ry8rVHHRiTcLGxZTT25JCJVkq9laRbqJQarZSyrTjqRESkNtAG8FdKVUUTqo2wXivz4OnpSQ1/fwDy5MmDr29FLlxwXHHZ2bL2CaYE7t27R0JCAjExMXh6PiYtPwuk9xk18PPgzJU7REQ9+KvZPrgUi3edBcCneD62HdE0IaNu/8ut6DhqeBd6yJaltAQAb74xkolTPrA6HhYcUpd8KepuWLOSTl21Flunrr3YsHrFQ/WW/7qQZztYkgJ4GGd8b9u3baa0dxlKlCxlu/AjQJ6SvNWZAU8gSin1L2hCEUqpCyLynoiE62kPvtLVu5Naex+IyJ8iclxE6unnc+hJtw6KyAIgR9IHiMjnuqr3ERF5ZMIa586eZf/+fQTVdLzh60xZ+2LFizPildfwLVeKsqWKkTdfPpo2a54mWyJC29YtCAkO5NtvvkqTDXPS8ow61irFEj0IJhHiW4Srt2I5ffkOAIfP3aB1gBeuLkIp91xU9y6EVyH7FIdWrVhOsWLFqFK1mt0+JXH16hWKeGipI4p4eBKVQjX+XkwM2zZvoFVb24tAnPW9LVuyiPYd7wfj7776gsYhAbw6dDA3b95w2F5aeOITbGUS1gMl9EA3W0Qa6Oc/U0oFKaX80AKduaigm1KqJppMWdLs+hAgRm99TuJBQdwxujxSVaCBiFS15ZSjaRLu3r1L9y4dmfbRJw8kSLIXZ8ra37hxg5Url3Pk2GlOnj1PTHQ0835J21snm7bu4I8/97B0xWq++nw2O7b/niY7kLZnlMXVhVYBXiwN++eB8x1rl2bJH2eTj3/adooL12PYOrEVU3oHEnbiql1vfsTExDDtg8lpytNiDxvXrSKwZm2bXWpwzvcWFxfHujUradu+IwB9BwwmdP9fbNwRThEPD8aNeTNN9+EIAri5iNXNLjsiriKyT0RW6sfeIhImIidEZIGIZNXPZ9OPT+rXS9uy/UQER6XUXbRANhi4CiwQkX5AI/1GD6FlRDRX6kzSjd8DlNb36wM/6TYPAgfNyncRLbPiPt1OJTv8sjtNQnx8PN27dKRr9560f66D1bKp4UxZ+y2bN1K6dGnc3d3JkiULz7Z/jrA/Uk+oZY0kH4oUKULbdu3ZHf5nmuyk9Rk1q16MA2evc/X2/df3XF2EtkEl+DX0XPI5U6Ji9E97qDd6NT0+3ka+nFk5demOTfunT5/i7Nkz1A6qTqUK3pyPjKRurQAuX7IvbYO7exGuXLoIwJVLFymc4ndlxW+LeLZDZ7tsOeN727xhLVWqVce9iJYJxL1IUVxdXXFxcaFXn/7s25u2cWNHcVLLcQTwl9nxB8B0pVR5NHHrJFXpAcANpVQ5YLpezir2LAKvoGfmO6wfVxWRd+x23UnoeV+2KqXeB4ahpTaYDXRSSlUBvubB1Ab/6j9NPDgr/1BTQUS8gdeBJnqrchVOTJOglOLFQQPw8a3IiFdHptmOM2XtS5QoSXhYGDExMSil2LplMz525sI2Jzo6mjt37iTvb9q4gUqV/Ry2k55n1LF26Ye61A39PDhx4TYXrsckn8uR1ZWc2VyTr5sSEzl2/ha28POrwtnIyxw9foajx89Q3MuLHaF7KOrhYZd/TVs+w+IFWutu8YKfaNbqfgfn9u1bhO3aQbNWbVOr/gDO+N6WLlnIcx27Jh9f1gM3wOqVy/Ct+BjUwG0sALen4SgiXsAzwDf6saA1khbrReYCSWMV7fRj9OtNxEa3y56W49fA20A8JLe4utlRz2mIiI+IlDc7VR1ISlASJSK5AXuSL/+OFlQRET+0LjRAXiAauCUiRdGUwp3Grp07+eXnH9m2ZTPBAdUJDqjO2jWrHbZjLmtfvUpFOnbukmZZ+6CawbTv0JE6wQEE+VclMTGR/gMHO2znyuXLNG1Yj+CA6tQPCaZlq9Y0b9HSYTtpfUY5soxZe0EAACAASURBVLrSyM8zeUY6iY61S7P4j7MPnHPPm51tE58h7H9teaVtZV743HKLq1/vHjRuEMKJ48eoUKaEtmzGTl4e1IcOLRty+uRxalUpy4Kf5jBkxOvs2LqZhkF+7Ni6mSEjXk8uv27Vcuo1bELOXLnssp/e7y0mJobft2yitdn45oT3RtMoxJ/GIQHs2r6NcZMffRZiAVxFrG5A4aRhK31LeaOfAKO4n/CvEHBTKZWUCD0SLVke+s8IAP36Lb186j7akSYhXCkVJCL7lFI19HP79URUjwURCQBmAvmBBOAkWhf7FbRAfRbtxs8ppcaKyFbgdaXUbj0Fwm6lVGkRyQF8j9Zl3g+UA4br5eYAwcBptFbncqXUHHNb1nx0VpoEZ5LoJCUVZw6OO+vNh8yoyhN151/bhezEWao8t+/FO8VOi4a1ObBvj9N+E7x8qqjhXyy1WubNxuVSTZMgIm2A1kqpl0SkIVrP73m0FC7l9DIlgNVKqSoicgRooZSK1K+dAmoqpa6l9vn2LAKPEpGy6N1REekEXLRexbkopfYAIRYuvaNvKcs3NNuPQh9zVErdI5VWr1KqXyrnG1o6b2BgkHacIDxRB3hWRFqjDYHlRWtJ5hcRN7116MV9Ye5IoASaeLcbmi6tVdlFe7rVQ4EvAV8ROY/WWhuShpsxMDAw0LAxGWOrg6GUelsp5aWUKo3W4NmslOoJbOH+EFtfIGkh8HL9GP36ZmWj22yPEvhpoKmI5AJclFK2p/cMDAwMbPCIXh98E5gvIhPRVp4kDRh/C/woIifRWow2501sBkcReS/FMQBKqUez6MvAwOCpR+tWO8eWUmorsFXfPw3UtFAmFrBvvZSOPWOO5u9jZUdbaP1XKmX/s8SbFFdup39Avkhe5wzEAxy76JxGfkk73yKxhwtOyhF9aW4v24Xs5J01fzvFzsRWvk6xAxAbZ3KKnfy5sjrFjr2Lsu1HcOGRtBydhj3d6o/Mj0XkQ7T+u4GBgUGaEHk6JMtSkhMjf4yBgUE6yeySZfaMOR7i/lslroA7YIw3GhgYpBkhc4hLWMOelqO5mEMCcNlsBbqBgYFBmsgMsmTWsNrrFxEXYJVS6py+nTcCo3189+Vn/L+9846Pomzi+HdIIPSiINJ77xB6B0UQlI6CUqSDYkNFRRErKFjwRQXEhl1RiiC9F2mhCoqCoHQB6UVJ8rx/zHPkCHeXu+TCHbC/fJ5Pdp/dnZ3d252dZ2aemVvrVuWWOlX4YNz/ANi6ZRNtmjWgRcMatGpSh40xgU/w79e7JwXz3kS1yv7NXx7++P00rVaMjs1qXez7bdsWure9hU631eahXndx+tRJQDNW9727FXXL5mXksMe8kQSgSrni1K9ZmUZ1qtG0waWpxcaOeYOcWdJy9MiRy44bNngADSsXoW3TBIfi4wO60/G2OnS8rQ7Na5ej4211LD9H6dXpdmqWuplXnhns1/UCnD9/nnq1a1CjaiWqVirHi8/7V/IoPi6OSQ+1Y8oL/S/pXzD+Jd7ulJDAadOsr/hk0J1MeqgtXw65h6N/7UiSdqC/mzvOnz9P0wa1qFezKrWjKzLipeEALFm0gIZ1qlO/VjWa39KAP3YmzUdizJ0zm4rlSlGudHFGvTYy4OOTC+EqT3ZrjIkHNomI99THYQhPWcNFZLedSph43ztFxGOtARFpJCKeZub4xPZftvLlpA+ZPm85s5euZcGcH9m1cwcjhj/NQ08MZdaSNTz61DBGPP90wNfWtXsPps2Y7ff+d3TowthPvruk74UnB/HgkOF8M+cnGt/WikkT3gYgKiqKAYOH8sjTL/pFe+rM+SxeGcOCpasv9u3bu4cli+aTv4DnR+bOjvfw3qdTLukb9d4nfDtnJd/OWcktLe6kaQtNppEuKj33P/YMg5952e/rdV3H7HkLWbN+E6vXbWTunNmsXrUqyePW//ApNxa41Jx+8Pef+ffMyUv6SjdsRff/TafbmClUb9eLxR8kmeAl4N/NHVFRUUz7cT7LV69n6U8xLJg3h7VrVjH44QeY8OEklq2KoUOnzox+9ZWA6AYzs3zAuAoKbPkjoPMAW21mnumultqMJReBZg03xkw3xlz2ybRTjBrhedqiT+z47VeqRNcgQ8aMREZGUrNufebMnIaIXNTSTp08cTEBaiCoV78BN9yQdN4/F6rVrEu2bDku6fvzjx1UrVkXgFr1GrNglv6cGTJmokr12qSLSn5ComeefIznXhzh9eGOrlWPbNlzeNxmjGHOjCm0aK0THDJmzETVGnWIigosvElEyJw5M6Bp0GIvXEjyZTt15CC71i2hwq0J+Uvi4+JY+vEoGvS4VIuOypj54vKF8+f8Mp4F+ru5I/H1XLgQe1GAnLLP08kTJ7g5T2DPU7AzywcCPxNPhBT+2BxTLSt2KuGyrOFwMXh9kIjcAaQFOhpjfrV5IaONMQ/Y5BP/AFXs/7pAnIjcCwwyxizzh4GSpcsx6uXnOPbPUdKnz8CieXOoWLkqw14eTbeOrXh52JPExxu+n70ouFfuJ4qVLMOSeT/SqFlL5v84lUMHAs8mLiJ0aNMCEaH7fX3o3rMPs2b+QJ68eSlfIfBs2QAxq1dwY86bKFSkeLKOd0dcXBx1alRj584d9BtwPzVq+s4qvmjiCBr0eIz/ziWE9W6c+TnFajQm8w03Xbb/hpmfEzPtE+JiL9DppY9SzG9SiIuLo1HdGuz6Ywe9+g4gunpNxrwznk7t7iBD+gxkyZqVuYtWBETTU2b5NWtW+zgiuAi9+PMNfzTH240xS9wbcHtqM5YCeMsaDio0qwLvoVk8PKEkcIsxpj0wDk2cWdmTYHTPBP7P0YRM4CVKlab/g4O5p31LunW6g7LlKxAZGclnH03g2ZdGsWrLToa9/BpPPNg/Mckrgudee4dvPn2fLq0acOb0adKmTRswjZnzlrBo+Vq+/n4GH77/HiuXL+PN0SN4cujwZPM1a9rki1pjShEREcHqmI3s2L2XdWvXsPXnn73uu3PtIjJmu4HcxRPSv50++jfbV8yhSivPweZVWt5D7wlzadB9MKu+HhcUnn0hIiKCZati2Prbn6yPWcu2rT/z3tgxfPP9D2z9/U+63NudZ570bSdOjGBmlg8cQpo0vluo4Y9wvNVD35UpT5YM+MgaDp6zgyfGt8YYv6YnuGcCv+HGS7M7333vffy4aBXfzlhA9uw5KFy0ON999dnFOiEtW7dn0/rQpDgrUrwk7346lS9mLKX5nR3IX6hIwDRcRZ1y5bqJ2+9ow8oVS/lr924a1qlGlXLF2b9vL03q1+DQIf+yZcfGxrJg9nRuu7N9wLz4Qvbs2WnQsBFz53q39+3ftoGdaxbxfu+mzBg1mL82r+bjB+7g+IG/+KDfbbzfuykX/j3HB31vu+zY0vVvZ8fqBUHl2ReyZc9OvfoNmT93Nj9v2Ux0ddWI23boxJrVPwVEK5iZ5QPFVe2QEZEBNsaxlHVsuNouLi0vEHbwkDXc9cZ5yw7ujqBUVjxy+G8A9u39i9kzptG6fSduujkPq1ZofZUVSxdRuFjKh4/JwT+23k18fDwTx46i/T09Azo+cfbvxQvmUaVqNL/u2s+GrTvYsHUHefPlZ+GyNeTO7V+27FXLFlGkWEluzpMv6Z2TwOHDhzl+/DgA586dY+GC+ZQq5X1qX/3uj9Lvo8X0mbiAVo+/TsGKNXngy9UMmLSMPhMX0GfiAtJGZaDXhDkAHNu/++Kxf6xbQo68qVvB78jhw5xwu57FixZQsnRpTp48wY7ffwNg8cL5lPRxjZ4QzMzyyUG4O2R82Ry/AGYBIwB3b+4pY4zPPGihhIiUAuKNMb/brsrAn0CFZJA7heaJCxj9e9zNsX/+IW3atLzw2ltky56DV996l+FPP0ZcbCxRUekZ+cY7AdPtdm9nli1ZzJEjRyhWOD/PDnueHj17ed3/qUE9iVm1nOPHjtK8Vhn6P/IUZ8+c4ZtP3wegyW130LpjwtCxZd0KnDl9kgsXLrB47kze/XQKBW+segnNw38fonsXHf7GxsbRvtPdNL31cq3KE564/z7WrVrG8X+Ockv1Ugwc/DTt7u7O7OmTadH68rwAzWuX4/SpU1y48B8L58xg/OfTKFbStxA4eOAAfXp2Jy4ujngTT/sOnbi9ZSufxwSCDTO/4K+NK0kTmZb0mbPS/OERSR4T6O/mjoMHDzCwb0+9nvh42rbvQPMWrRgzdjzdunQiTZo0ZM+RnbHvTQzoOtwzy8fFxdG9R89kZ5YPGBL+M2SSzAR+tcFH1vB1qOPliIhEA6ONMY08OGRmGGMmW1ol0XoT8SThkKlYuZqZsTB5BarcEczEE7/sO5n0Tn4gHBNPlLg5c9I7+YlrOfFE+nQRQaFTt2Y0MTHrgibNiperZF77wndoU/vKeb1mAr8SSM7c6rCGj6zhhd32WYeG6WCM+Rj42C73SETrNxLqzDhw4CCICHfN8ZoTjg4cOLg6EOay0RGODhw4uPJQb3V4S0dHODpw4CAEEGdYfb0gbYQE1ZkSDJTJlyxHe6oiWI6Us/8GL/9JsBwpOW59KSh0AI7Nu6yoZrJw9PR/QaETG6Qyv+4Ic9noCEcHDhxceYgQFvOnfcERjg4cOAgJwlw2OsLRgQMHoYE4DhkHDhw4uBSulGXhjHCY331dIFgZl4OZuTnceEopnbi4OBrViaZzh9YAtLy1EQ1rV6Nh7WqULV6Qe+8OPKlFoDwN6lCDmI/6se7DvnzyTFui0uoMleG9GrF50gA2fNyfge2qA5A1UxSTX+7E6ol9iPmoH12b+5fqLSX36f13x9CkdmWa1q7C/b26cv78eR4Z2JvalUrSrH51mtWvztYtmwKimVyI+G6hRthpjiIyFOiCJoeIB/oZY4KSZE5EGgGPGWOCN9HWD7gyLs+cNY98+fNTr1Z1WrW6kzJly4aETjjyFAw64999m5KlylxMADtz3uKL27p36USLVnekKk95c2ZhYLsaVOkxjvP/xfLZc+3o2KQcIkL+m7JSqft7GAO5sut0zH5tovn1zyN0GPoNObNlZNOkAXw1fwsXYuODxpM7Duzfx4fj32Hhqk1kyJCB/vd1Yfr33wAw9IWRtGrdLqD7k1KE+7A6rDTHQLN4X0nYzODJQrAyLgczc3O48ZRSOvv27WXu7Fnc2/3yDEOnTp1i2dJF3N6qdarzFBmRhgxRkUSkETJEpeXA0dP0vbMqr3yyDFcag8PHzwKaTzFzxnQAZMqQjmOnzhEb510wJpcnd8TGxnH+/DliY2M5d/YsuZORjT4YEHxnAQ+HIXdYCUc8ZPE2xuy39V+eF5H1IrJFREoDiEgmEflQRNaKyAYRaW37C4vIMrv/ek91YESkuj2mqA86PUTkWxH5AU2imyx4yri8b1/g2beDRScceUopnaFPDGb4SyNIk+byR3rmD1Np0LAJWbMGFvcZKE/7j5zirW9+4revH2TXdw9z8sy/LFj3B0Xy5qBD47IsH9eTqSPvplg+LRMxbso6ShfMyR+TH2Ldh315bOxcksoDk5L7lCdvPvoNepiaFYpTtXQhsmTNRsMmmq71tZeGcUvdagx/+jH+/fffJCgFAUkMqcNANoadcAw0i/dQYKExpjrQGBglIpmAv4Fb7f53AW+7n8QKy3FAa2PMHz7oANQGuhtjmiT3ooKVcTmYmZvDjaeU0JkzayY5c+WicpVqHrd//+3XtOt4V6rzlD1zelrVKUWZzmMp2mEMmdKn5e5byhOVLpJ//4ulXv8P+WjmBsY/ocP7W6sXZfOOQxTtMIaavd/nzQebk8VqksHiyR3Hjx9j7o8z+GnjdmJ+2c25s2f47usveHLYiyxZs4WZC1dy/Ngx3h0z2i96KcHVUEMmrIRjMrJ4NwOeFJGNwGIgPVAQrRHzvk3W+y3gbpApA0wA7jDG/JUEHYB53vJXupdJOHzksKddgOBlXA5m5uZw4ykldFavWsnsH2dQuWxx+vS4h2VLFtGvVzcA/jl6lPUxa2nWPPDKHoHy1KRaEXYfPM6RE2eJjYtn6rJfqVU+P/sOn2TKUk2LNm3ZdsoX1Zo0XVtUYtoy7f9j/zF2HzhOqYKXFchMEU/uWL54IQUKFebGnLlImzYtLe5oQ8yan8h9cx5EhKioKDrd0y1ZJYOTA0mihRphJRwh4CzeArS3NV4qG2MKGmN+AR4BDgGVgGjA/XN8ADiPFtEiCTrgIzO4e5mEXDlzedstaBmXg5m5Odx4SgmdYc+/zM+/7Wbjth28//Hn1G/YmPEfTAJg2pTJNGt+O+nTB15RMVCe9vx9ghpl85EhSh/PxlWLsP3PI/ywfDuNqhYGoH6lQuzYq9/aPYdO0qiqlqi4KUcmSha4gV37jwWVJ3fkzV+ADetWc+7sWYwxLF+yiOKlSnPo4AHAVn+cOZ1SZa5cwttwlo5h5a1ORhbvOWhFwUHGGCMiVYwxG4BswF5jTLyIdAfcM34eB3oBc0XkjDFmsQ86QUGwMi4HM3NzuPGUWlmpp0z+hocGP5GsYwPlae0v+5my5Bd+mtCb2Lh4Nv1+iA9mbCBDukg+eqYNgzrU5My5/xgwegYAIz9dxoQhd7L2g76IwNAJCzl68lxQeXJH1ega3H5nO5o3qklkRCTlKlbmnu696drxTo4eOQzGULZCJUa+Mdb/m5QChHviibDKBJ6MLN4ZgLfQ5LYC7DbGtBKREsB3wFlgEZrFO7N7KI+IFETLQPREa+J4otPDnveBpHivVi3arFgdmoJZ1yOCmXgiY1RwdIRrOfHE7Y1rs2lDTNCkWZkKVcykaYt97lOjWHafmcBFpAAwCbgZDfubYIwZIyI3AF+j5rfdQCdjzDFR4+wYtHrqWaCHMWa9N/phpTkmI4v3OaCfBzq/c2kG76ds/2LUpoi1N7p/cj3R+RibJdyBAwfBgxCUMrCxwGBjzHoRyQLEiMg8oAewwBgzUkSeRGtgDUGrppawrSbq3PVa0DzsbI4OHDi4DhCEUB5jzAGX5meMOQX8AuQDWgOf2N0+AdrY5dbAJKNYBWQXEa+Bno5wdODAQUjghz8mpysaxLa+XmmJFEadrKuB3MaYA6ACFLjJ7paPSyeV7LV9HhFWw2oHDhxcL/CrNvURf6oPikhm1MfwsDHmpA+6njZ4dbo4mqMDBw5CgmDMkBGRtKhg/NwY44qFPuQaLtv/f9v+vUABt8PzA/u90XY0x2sY/14ITu3jyIjgfUODFR2RLjJ4PJ0P0n06OmdoUOhA8DzfwfJ6R6YJbtiNOmRSSENVxA+AX4wxb7htmg50B0ba/9Pc+h8Qka9QR8wJ1/DbExzh6MCBg5AgCFl56gJdgS12dhvA06hQ/EZEegF/AR3tth/RMJ4daCjPfb6IO8LRgQMHIUFKNUdjzHK8z6Vp6mF/A9zvL31HODpw4ODKI0wy7/iCIxwdOHAQEjjJbh2wZ88ebrulMZUrlKFqpXKMfXtMsmn1692Tgnlvolrl8gEdd/78eZrUr0XdmlWpVa0ir7w4HIAJ771DlfKlyJ4xkqNHjvhFa0DfnhTOn5vqVS6f8j7mjdFkjkrDEb9p9aJIgZupUTVhQtPmTRtp3KAOdWpUpUGdGqxbuyZJOnv37OH2Zk2pVqkc1atU4N2xmqVuynffUr1KBbJmiGR9TNLTO8+fP0/T+rWoV7MqtatVZIS9Ty488ehD5M+Vza9rS4z/jXmT6Mrlia5Sge5du3D+/Hmf+wdSciF75vR8/UIH1kzsw7J376NsYe+JUFwI5nMZKFwOGSefY4ghInEislFENnlLfpuaiIyMZORrr7Nxyy8sWb6K8ePe4Zdt25JFq2v3HkybMTvg46Kiopg+az4rVq9n2aoYFsybw9o1q6hZuw5TZ86hQMFCftO6p2sPpv4w67L+vXv2sHDBfAoULOjhKG+0ujNl+o+X9D379BCeGvosK9esZ+iw4Tz79JNJ0omMjOSVV0cRs2krC5euZMK4d/n1l22UKVeez7+eTN16DfziJyoqimmz5rN89XqWut0ngA0x6zhx4rjf1+aO/fv28d47/2PZT2tZt2EL8XFxfPvNV173d5VcqNvvA6J7TiAiQujYpBxdm1e6WHKhSo9xfLtwKwBP3FOXTTsOUaP3+/QaMZ3Rg5olyVMwn8vkwBGO4YFzNhVZJXSe9YgrefI8efJQpWpVALJkyULp0mXYvz95Gbzr1W/ADTfcEPBxIkLmzJkBuHDhAhcuxCIIlSpXoVChwgHzkCPH5TwMefxRXhrxakBzZj3REhFOndQ6MCdPnCBPnqRT+d+cJw+VqyTc41KlS7N/3z5Kly5DyZKl/ObH232Ki4tj2NAhPP9S8guIxcbFcu6clig4e/YsefL4zsMYSMmF0oVzsnj9bgB+23OUQrmzc1OOTF4oK4L5XCYHksRfqHG9CEd3ZAWOgUbWi8gCt/ILF4uMiMizIvKriMwTkS9F5DGvFAPAn7t3s3HjBqrX8DrfPdUQFxdHvZrVKFEoD42bNiU6iDzM/GE6efPmpUJF/yro+cLI0W/yzFNDKF2sEEOfeoLhL74S0PF/7t7N5o0bk319cXFx1K9ZjZKF8tDI3qf3x71Di5Z3cLMfgtoT8ubLx0MPD6Z08UIUK5SXrNmyccut3rW7QEsubNn5N60b6EcgunReCt6cjXy5svjNXyieyzTiu4Ua14twzGCH1b8CE4EXbf95oK0tp9AYeF0U0WiS3SpAOzRh7mXwNxO4C6dPn6Zzp/aMev2tgOuZBAMREREsXx3D1t//JGbdWrZt/TkodM+ePcuoV1/hmedeCAq9DyaMY+So1/l155+MfO117u/fx+9jT58+zb2dOzJy9BvJvscREREss/dp/bq1rFi+lKnfT6bvgCQz13nFsWPHmDFjOlu3/8GO3fs4e+YMX37xmdf9Ay25MPqLFWTPnIFV7/dmQNvqbPr9YJLFulwI2XMZ5slurxfh6BpWlwaaA5NsdL0Ar4jIZmA+Ogk9N1APmGaMOWezffzgiai/mcBBh2idO7Xnrs730KbtlS2BmRjZs2enXv2GLJg3Jyj0/vhjJ7t376J29cqULVmEfXv3Uq9WNQ4dPJgsel98Nok72+g9atu+IzHrknbIgN7je+/uQKe7u9C6TcrvcTZ7n5YvWcyunTupWr4UFUsX4+zZs1Qt7/9QHWDRwvkULlyYXLm0RMGdbdqy+qeVXvcPtOTCqbP/0e+1H6jVZyK9RkwjZ/aM7D6QtH00VM+lvnzOsDqsYIz5CcgJ5ALusf+rGWMqo6UV0hPk75Yxhv59elGqdBkeeuTRYJL2G0cOH+b4cX1Zzp07x5JFCygRgC3OF8qXr8DuvYfY9tsutv22i3z587N8VQy5b745WfRuzpOX5UuXALBk0UKKFS+R5DHGGO7v15tSpcsw6KFHknVe0Pt0wu0+LV60gEpVqrJ99z42/7qTzb/uJGPGjKz/eXtAdAsUKMja1as5a0sULF60kFKly3jdP9CSC9kyRZHWTqm8r2UVlm/+i1NnfSe6DelzmcSQOhyG1dddnKMt6xoBHEXLKfxtjLkgIo0Bl8t2OTBeREag96gl8H5yz7lyxQq++PxTypevQM1qlQF4/qVXaN4i8KJP3e7tzLIlizly5AjFCufn2WHP06NnrySPO3jwAAP69CQuPg4TH0+bdh1ofnsrxr37P95+YzSHDh2kbo0q3HpbC/733gSftHp07cKypYs5euQIJYsWYOizw+l+X9I8eMJ9XbuwbNkSjh45QqliBXn6mef437vjGfLYI8TGxpI+fXrefmdcknR+WrmCL7/4jHLlK1CnhjoZnnvhJf79918ef/Qhjhw+TIe2d1CxYiWm+vD2Hzx4gIH2PsXHx9PW3qeUonqNmrRp1566NasRERlJpcpV6NnbawaugEsulC6Uk4lPtSYuPp5fdx+h/6gZSfIUzOcyWQgDAegLYVUmIbUgInHAFtcq8LQxZqaI5ESHzGmBjehczRbGmN0iMhzojNawOQwsNsZ4FZDhWCbhWk48EUzExgcpGUYQ79ONt70cFDrBSjxRt2Y0MTHrgibOKlSuZqbPX+Fzn6K5Mvgsk5DauC40R2NMhJf+I2hdak8YbYwZLiIZgaXA66nFnwMH1xvCxOfiE9eFcEwmJohIWdQG+YmvQjwOHDhIBsJcOjrC0QuMMV1CzYMDB9cywr00qyMcHThwEBKEt2h0hOM1DVeigvBCcF6J8/8Fx9kEkD5dcO7TibMXgkIHgudIydEoOHT+3R7kaYUSlNKsqQpHODpw4OCKIxhlElIbjnB04MBBSBDmstERjg4cOAgNHIeMAwcOHHhCeMvG629udSgQzIzLc+fMpmK5UpQrXZxRryU/t2AwaYUDnfPnz9O0gc3gHV2RES8NB2DJogU0rFOd+rWq0fyWBvyxc4ffNIPxu504fpxeXe+iXnR56levwLo1q+jbowtN60XTtF400RVK0LSe/5NAzp8/T73aNahRtRJVK5XjxeefS/KYQZ3qEPPpINZNGsQnwzsRlS6SRtWKsvKDgaz66H4WvNuHovk0p2aB3NmY/XZPfvpwIGs+foDbapUM+Jr9RZgn5dHpXKnVgLaAAUr7se9uIKeH/tMBnnM48FgQeC8MdPF3/6pVq5lzF4zH9sdf+83K1THm3AVj/v7npCleooRZv2mr1/29tdPnY02RokXNtu07zYkz/5oKFSomi04waYWKzrEzsZe0f05fMHsOHTfHzsSav4+fM9Wiq5u5i5abYsVLmFUxW8yxM7Fm1Jv/M53v6XbZscH63Q6e+O+y1rHzveb1t8eZgyf+M38dPm22//n3Jdv7PfCwefzpYZcd5+0cZ/+LN4ePnTLnLhhz8ux/Jrp6DbN42U9e9y/aeqTZte8fk73xcyZ93aFm8oLNpvdLk81vfx02lbq8ZdLXHWoeHD3NTJoZY9LXHWomTltjzy8LcQAAIABJREFUBo2aZtLXHWoq3/OW2b3/H5O+7lAjmW42wZQNlapUNX+fvOCzAetSUz4l1VJbc+yMJnG4O5XPkxooDAQlEDxYGZfXrllDsWLFKVK0KOnSpaPjXXcz44dpSR+YirTChY7HDN4imlX8VEJW8UCS1ab0dzt18iSrViynSzctj5wuXTqyZc9+cbsxhh+mTKZth7v8ppn4OmMvXEgyJEYziqclwv4/cOQUxhiyZooCIGum9Bw4csryxMX+bG79qYIwVx1TTTiKSGY0kUMvrHAUkUYislhEJtss259Lol9WRDKIyGwRuSzDqYg8LiJrRWSziDzv4/SVRGShiPzuomOT2I4SkZ9t1u+7fPWjhcHr2yS5yc+BlQgpybi8f/8+8ucvcHE9X7787NuXvPizYNEKJzpxcXHUr1WNkoXz0KhJU6Kr12TMO+Pp1O4OypUoxDdffc7Dg4cEzBsk73f7c/cf3JgzJw8N7M0t9arz6AP9OHPmzMXtq1YuJ2eumyhaLOmUbO6Ii4ujZrXKFMx7E01uuZUaNb3ztP/IKd76ajm/ffcYu6YO0Yzia3cwcORUpozqxo7vH6fLbZUZ/dlSAF7+cAF3N6vEju8fZ8robjz6VtLZfZKLcE9ZlpqaYxtgtjHmN+AfEalq+6sADwNlgaKoAHUhM5ol5wuTKAOOiDQDSgA1gMpANRHxVjWpIppmrDYwTETyohm9KwOVgFuAUSKSx0f/k8Ayo0ly30z+bUhASjMuGw8ZbZIbSBssWuFEJyIigmWrYtj625+sj9FM5++NHcM33//A1t//pMu93XnmycCrXST3d4uNjWPLpg306NWP+cvXkjFTJsa++drF7VMmfx2Q1uhCREQEq2M2smP3XtatXcPWn71ndM+eJT2t6pWhTKfXKdrmVc0o3qwSg+6qQ9vHJ1G83Sg+/XE9rw5qAUCnWyry2awNFG83iraPTeKDZzqkUrB2UqluQy8dU1M4dgZc5dW+susAa4wxe40x8WiasMJux0wDPjLGTPJAr5ltG4D1QGlUWHqCK4v3EWARKlDrAV8aY+KMMYeAJUB1H/1JIpAyCcHIuJwvX3727t1zcX3fvr3kzeu7SFNq0wo3OpCQwXv+3Nn8vGUz0dVVs2rboRNrVv8UEK2U/G558+UjT778VI2uAUCr1u3YvGkjALGxsfz4w1Rat+sYEE13ZM+enQYNGzF3rvf8lE2ii7H7wDGOHLcZxZduo3aFglQonoe12/YCMHnhFmqV14qR3VtV47uFKmxXb91D+qhIcmbLmGweveG6Lc0qIjcCTYCJIrIbeBy4C70n/7rtGsel4UQrgBaJh9oussAIq8lVNsYUN8Z8ICL326HvRqshgjqB3GHwbsVI9s9g/CyTYExwMi5HV6/Ojh2/s3vXLv777z++/forWra6M6S0woWOpwzeJUuX5uTJE+z4/TcAFi+cT8lSpf2mmdLf7abcN5MvX352/K5Zw5ctWUjJUpr9e+niBRQvWYq8+fIHRPNwoozuCxfMp5SPa9pz6AQ1yuUnQ1RaABpXK8avuw+TNVMUxQvcCECT6OJs//Pwxf0bVSsKQKlCuUifLpLDx894Jp5ChLtwTK04xw7AJGNMP1eHiCxBtTRfGAY8C7wLDEi0bQ7wooh8bow5LSL5gAvGmHeAd9zOA9DaZvHOBDRCh8gRQD8R+QS4AWiACu1IL/35AP/Lt/lAsDIuR0ZG8uaYsdzR8jbi4uLo3qMnZcuVSxZPwaIVLnQOHjzAwL49iYuzGbzbd6B5i1aMGTuebl06kSZNGrLnyM7Y9yb6TTMYv9vLr73JwN7duXDhPwoVLsJb7+j5p373DW3bBz6kPnjgAH16dtfrNPG079CJ21t6z1S+dttepizayk8fDtSM4r8d4IPpa9l3+ARfvtSZeGM4fuo8/UZ8D8CTY2fx7hNtGHRXHYyBPi9/HzCP/iIchs6+kCqZwEVkMTDSGDPbre9BVODtNMa0sn1jUXf9x1bDjEbLF3wIHDbGPCEip40xme3+DwG9LcnTwL3GmJ2Jzj0cyAsUAwoCrxlj3rfa6GtAC1STfMkY87WP/rTAbLTezMdJ2R3DMRP4tYxrPfFEtoxpg0InaIknNn5A/OkDQZNmVatFmyUrfBdOy5ohIqSZwK+LMglXAo5wvLJwhKN/CGvhuDIJ4Zg+tMLRmT7owIGDkCDch9XO9EEHDhyEBCmNcxSR5iKyXUR2iMiTQecv2AQdOHDgwC+kYIaMiESgjtgWaMx0Z1vzKWhwhKMDBw6uOARNWearJYEawA5jzB/GmP/QWOrWweTRsTkGCevXxxzJkFb+TGK3nMCRIJ0yWLTCjU4waTk8BY9OoSCc5yLWr4+ZkyGt5Exit/Qi4u7lnGCMmWCX8wF73LbtBQKfk+sDjnAMEowx3qPALURkXbC8b8GiFW50HJ6ubp78hTGmeQpJeFItgxp64wyrHThwcDViL1DAbT0/sD+YJ3CEowMHDq5GrAVKiEgREUmHZv6aHswTOMPqK4sJSe9yxWmFG51g0nJ4urJ0rhiMMbEi8gA6rTgC+NAYszWY53BmyDhw4MCBBzjDagcOHDjwAEc4OnDgwIEHOMIxBPCSr9JBkCAimcPxHocjTw68wxGOqQwRuUlEctjlWwBMMg297i+XiESlkC/xtJwSOink5wa35VIpoFMC+BQtfZFSnoLmsBQRcf3uIhJ4jQwvNFNwbBa35dzB4OdagyMcUx/lgC9sQbBXRJKcFeARiV6u+4AOIpI+mbTSuNFqb3lMKU93iUjb5PIDNBGRt0WkPzAkuQLEGPM7sAt4UkQqJoeG5SkbtlyGiNya0nm7bvepLzBeRCJTKNxKAt1sGEugx0ahGfe7ikg3NNlzsp6laxqhrAt7LTdsJIBdngT8BzS062lTQHcgWkOncOLzJINWLWAqkCOF1/oY8BNQJlF/mgDpbAD+AQoEep+w03Xd1kcC3wEVk3lNJYEhaF2jX4FMQXgmGll62VPyTAH1gclorF8nICpAOmmAMsAv6BS8G2x/REqv8VpqjuaYCkikmfUEtgNvAaNFpIwxxu+sqImGv1mAe23bLyKdgWd9VGH0SlNEGgPLgFnGmGMp0EKLA62MMbWBv6yW9QSA0SJqPvlwW44CFqB1zkeISKS/98mlwRpj4kXrF2GMeRLYBjwfiAbp4slo1cx8aIKDb7i09lFAtOzyjcBtll5gtVgtjDFGROoD7wEfoAXqGgB3+aNBul1bPHACOARswZZONsYEL4PwNQAnzjEVISK3oSmVRhhjDonIC8CdQHPbChpjXvBxvPuw9UFgHdDY0vgNLVB2GMAY83gSvFyk5db3EXCrMSa/XY9I6gVJxFNmdD7rXHTq1jEgHSoAplsB5Q+dMsBJY8w+u/4lEGmM6SgijVDNaI4vvuxxD6DJB/YAHxhjdoqWzSiH/gbrA7i27mip3oWoMPsHLRm835pGjia+nz5oZQTOoQkeHkdrG71rkhG0bD88mY0xw+wHpRfQFpgITDGaoSYpfgqjv9UpoAKqIW82xowUkerAKWPMr4Hyds0h1KrrtdTQF7MhOmzJDcSjDywkfIheQIXJGvwc8qE1uKejc0nzo2Vu89ttvYAv8DEkcp3bLrcFegDRdn0SqoFE2HV/6TyAFkNLg5bJHQWUtdvaA8+57++D5iPAUlRrHG/pZQG+R80HG4BiftDpY+nkB3ag2l59u20U6qTxOvwEsrot1wK+RIUQaCqst4AHgaeBt4H0fv52g4FP0JkctVFH0bPAGH9//0T07rS0yrr1zQPeBCr4cfzj6IhhGzACLXrXEDWvzEQrgOYL9bsUDi3kDFxLDdUG8wJ57Xp9VGPonGi/YsCNftIsBqwExtl1d7taLys8yvtJazBax/tpYDVwm+3/GPgLP22EQF9gFVZAJ9r2ALDJH55Q88Ayu/wKcAadBuba3gFrW/VwbHUrtKKAzFYA3mwF2HzU5jjHTUDmTOIePwWkB3IAU1AtvY7bPi2tUPvJX6EGdAHm2eUY4D27XBYt6vYakM7H8a4PajWgKVowLp29V0NRDb0kMAu1rz6bBD817bMUaZ/T14Dh9v4VRqt/lg71exQuLeQMXAuNSzWqAqjG09GuNwZOAl0CpWXX06Na0VagvVt/UftgexVCifjKjQ4LQbWHH3HTpIBxQNEkeEtj+ZkM3AHkssLwA0szp31JPfLk4doq2hf+ftRRkQ3YiWqNkUnw0gXVvlva9XRWyM1x22cnqh1lTIJWESA7qtUVR3MXTgIexU1rtdfv1TFDoo8L6jxrjGrHs133GxXo+fAtsF2CsQVqQnkGtRFGW2E5BP1ArUY1945W2EUkpuG2Xh39cGS163mAzcBdoX6HwrGFnIFroXl4CLugw8T2dr0+OsTu6C8d1Ej+EGr3usmuTwXauO3jVetIRLeIfbE/RYebM7CeYKArPoZRiXhyDb17oJ7SmcBLaMndd+05PA5dE9HJ5vaCprGCqIVdf8G+9Lm80HHXnF9EHTiuD1FB1LNcC9Xivwvg2rIAL6OCvjBQyt6vR4ASAT4Pza0AHIgOYSe73e+ngP8lfma80CmHNSugzpxD9vqa2u25UE33NnSYXN7LtWUE0qIfgHfQD9uNdttzJBrZOM3et1AzcDU31KHiWu5qBUVlu94aWAK0s+t1gFJ+0u2HDn86okPN1vbBvhsdFt8RAI8l0GFzHlS7WwNUs9vuA37Gw/DYAx3X9bVBtZdy2BAgy9dS/Ah3QcN+pqJ2zntQG+Hj9qV9DtUa/eFnIGoX/Bx1wLS1/f1Ru1kMUM7H8ZcJJ1TrH4pq0YXRIetUVLP1qskCVUkYvmdBh94R9tpWAk+ijo/u9rrLeqFTDGgHtHbrKwnUReu7g2qM/wFN7HpW1Fbr8VqBh+09WoR6tp9F7ZMTUUH9BwEK/+ulhZyBq7UBN6JDwb5WeK22D+kU4F67z532ZbjTT5ppULvZJ5Z+V1QDdWlsWazALBAAn8VRDao2qmm4NLMJ6FDdqwBxo9Ef1dDuRG2T/Wx/BNDT0vE2lK6G2sayA01Q4ZwVjc8bj2qhNVEt+Yek+EHjGYuhNkFXPGRnVJPtYNdvAm7yQaOo2/LDwEeovS03ahoYhgrrovb+5fVBKxLVnBcCdW3fGmwsIxpPONG2KT6EWEn0Q/U6KlD7u23rjXq3QZ0nC4Fabts9xoOiGmIM+mEcgjqB2tpnYQD6sfPrg309tpAzcLU21PbWCvgMWAzktv3d7Ytwj12/HSjkg44nDeZpVGOZgx1GovYvv72bqMboOvY++8LmsHxHo1qERyHLpUOytOiQOScqrOeTIKzzoU4Vj0Z81Imxyd6T/MBdwKdu25uhgchFXefy5x6h9sUvUXNFpO17AQ1NaZ7EfbkRjTt9BhXay+w1vIpGBOSx+4wE3iAJ26cbzb6ocG+Khg2B9WiTEGTtUbNGHTQbsCMCy88AEkYh9VFzyBj0I1DD27OTiO6DwFtu613t8Tf4c/z13kLOwNXWuNTmFYHae3YBL7r1dwO+JglDdyIhdD/6dRcrHNditTFUW9wCFPeTVhl0KD0XdS5kszRv9eP63Ol0RrWwIehQ1d3ZMQgVsB493KiGswOo6dZXGdWK3fs+BOolPrcXfgpjbYio8+FZEmYK3W4FiC8bYyt7LU1QjX4OGsAOqlUPRz9K+YAb8MNh4raeFR3qr0Hty5NQrf8z4H37rHgURmg4Tbzb+mbUA73R3p8I1PY8nCSEvz3eZd9shNpQK7lt+5YEoesIR1/3MdQMXE3NgzBrjg6rWqBDpgfctncG8vhJdzA6bK1o1zOgRvtJqPPkoqD0g69slqfsVnh8aQXJYmB8ANfa2r7c+VHhPI8EzeZudAjo1VaFaroP2eVIN95eQbW0x9Ah9U682BgTXdej6PD9B3tsBvQD8Cn6IVqHD2+7FYybSBh657PHvO+2z41oSNBX+B/v2RS1CbpGDgPsve5p711h/IvTbIHa/+YDw2xfOtRTPdjb+e16Ibfz90GH5o+iJo2xqB21J6q5bwduDvW7dDW0kDNwNTbUPraWhKDntKgG+TXwhB/Hu79cmdCveRb7MnW1D3cx1OZVA/+F7EDUg/wpOpROi9rM2qBa3B7UrpbUcCzaCsb+dt2leX6GaqOrSSJcBxXuL7n6SBji50CHtBNRrcYfm2dNe+4iaNhKDDDEbqti75lXAYTacRcB1V333P6vj2r97h81nxpjIroPoJris8DvWAcdaqNdhrVBBvBcNQViuTyWdbCPY3KhQemPWgG42v7e81FHV0fLzyeo0PcrJtZpjnD0/0YlvPQ3ocOxAuhQqiOqLZRDtZPPrQDwJ1SjlP0/C9WIpgDPowb3t/zlyS7fjmpzxVD718uo9zeD3V7Qm5BF7ZO10OFmNtTuNgHVgCrYfdJZwVHSH+Fhac0nwTOehgQN8hFLx2fCBCtUK6HDzA9JsHUWskJpjJ+/XQ5UqFdAba7D7bV9jXrZ9wDPB/g83IKaGjIBT6COquMk2E/7EIDjLNHvuMMuF0dDd5olcUwHYDQaMtTG9uVGtUZ3c4/PeE+nJbqvoWYg3Btu4Tp2/UZU05tg/0+0L4lLy/Ire4t98L9FPYqZrJAtbLe1RKcEZvBxfHXU0eESft2BV+1yWjT4+GuSCIux51qPCub5wG6gPKrFPo9qgElqdx7oZrJC6DWXgLT9d9vzJekMcutzTQ2sQ4I9rQiqDfqjCQtqupiDlvT8GPUA10UdL4+hZg2PsZWe+EI/FHnsfZ9v+z5Fw2wCFoqJaDcHzqJmBK82Ri79OLZE7aWfk+DFz42GFXn1tjvNx+8QagbCudmv+O+ofcr9QWyMDltL2vW+qH0wSc+mG42b0GDxj4G73fofQW1jPufJosb2tSSEDUWjQ6pGbvv8gE2T5oVGczSsp6Fb33NWQJaxPD5neSyZjPuXDw2LWYJqNi+hmpA/Uws72Ptaya73Q7W/em4CMpD7nRkNYbkkxZf93W71JWAT/falcEvNhpoI7rfLvVAbsVfHWQD8NsXGbiaxnztvzdE54ENRk0wLbOhUar0j13ILOQPh2kiYdVDLrkeQMCx0T1LgCqQu4yfdizNSUHtRRyt8XLM8XsdLkLDdXgHoapcboMPD7ujQsb992XtZ4bIeL95bVPOJJ8Fbm95t2/PoRyEDOsXvcZJpxLc06qFaZD9vQha3IR8ae7jMCuZFJMRV9kY/ALWD9Bt3RO2Xfgkz1K63AJ0K+I29hw+io4i3Ue02qM4OX0Lbtd3tYxFhBeQ39rf/Cj+SUTjNy70NNQPh2ND4u0OoDadkom2N0Ji0vKh9b0ISwkwS/R8LHCAhOUVuNBh6Jf6FaXRBZ5F0ceNnMeqJLIYO06dZgVspCVot0RAh11Qyd41qMVAlcX8q3e+WqMaTD3W+fG37H7Mv+QQSzBbdSGTqSMb58lgB7DV43cMxt6K5L0E14Dl2+QY0MuFVf2mlgG93LTGdB/6+Rqct3oFGBXgNhHeaH/c71AyEW0OHM7+hU9seRW1Srji8XFZgtnXb32vqqkQPcx635aeBP90E5AP2PL5mYrjTaoeG6LiG1I1RDcsVeB6Bn1m00aHXThKmArq0kGkkM4t2gPfbFWLjciRksEKypRXQkajWuRWrQQbhnBksfb+Hv+gUwZ4uweh2n4KixQbIf0/7MemLOgILoE68Tm77ZL7SfF1rLeQMhFtDHR117HIpNLnBCNdLQEIeRb9LAKAB0z+iBvMBqOf3SdQ5MNK++IX9pFXeCoxWiQRkQzRoOOAkAh4EZDd0+JqqmgeXh9hkQDWf/KjW+LQbP++lNj9ufCV2vghqXlhjf0fXKKA3Ovz3KzohhTy5TDq9UOdRbdRD/qAVjmXc93NaylvQqqtdKzDGrIWLpQ62i8gk1E7YRkTijTGr7X4+SwC4YCsO9kVtQU3Qoe8zRjM5/4GGA7U3xuz2g1ZRNMbyV1RzALjH8vWFiNyPCtyAYIyZZbNoLxWRd9Hr7WWM+TtQWgHiX+ACcN6WaRiC2idj0eFqtC3DUAedn57a/ACXFMN6CBWKu1Gb4tuoXXegrdjXBv0YHUstXkSkljFmlTEm1hYdK4V+LGqjAd3v2m3pLe+xqcXL9QanTIIfsOU+u6BhPJ+7BKQfx6VDX6BGxpiBtq8+qhUNMsb85ePYy8oa2P4OaAjKn2iYTQusI8YY801AF3Y57VaoPbOKSUYK/2ScT1DTRTN0eDgf1Yp+QSMF9qEhLcuNMTuuAD8ZjTFn7XI9dMQwHhWQJUgQSuXRZ+ETo7VmUpOnqejwv7xdH4zaOP8xxjSzfY8AfxljvktNXq47hFp1vVoaOjPjKXxneynsttwPtU+VRV/4Fm7bvifpBAmRbsvtgUfc1tugWWMG2PXmBCm1PVc4UBjvITaf4Jbc9wrw4XIK5SUhBZv7vOsX7O+WImdQAPy4z5L5AoixyzXRj8jddv0u1GbrZPAO9m8QagaupoYPJwcJMZFZ7Is+DpuNBx1Wf4wGIt+FzvjwGpyNeh6/RO2SLewLsRk3hwQabrMet9RW10ojIcQmyTnJQTqfyynU2q4XsPd7nNs+N6IB7d+iQfYBlZ1NAW8uG/cUEkpKdEZnDC20QtwJ10mNex9qBq6FxuUxkV8Af5NQoCkf6gX/GnUsePUCWy1wDerEeRHNNVgFtcXFuGmLLgGcO9TXH8T7GHCITRDO6W3edT1SMO86Bfy4ZrcIGoXwvdu2qcBit/XCpLDmuNN8/BahZuBqb3iIiUSdLD9gKw+67XtxfrEXWq7AbFf2m4JWoLqyXNcFDqJBvttJxqyVcG4kI8QmCOcM+rzrZPIh9rn5g4RsRqVRJ5B7XZgpwO+h/q2uh5YGB8mGiDRFg7ofReew9hKR+saYk2ic5GkR+cq9mLrx4U00xvyDBvCOFJGsRh02seg0PowxK9Bpgp+ilQNT1RlwpWGMOWeMmWmugPPFDcfRuMXRaOaiwmgGoLfRwPwxQFMRyZWaTBjFSXTI3F9E+qLxqueMWy1xY0xbYJ6NXHCQinC81SmALYCe1hizUkRKoRmc0wI/GGNW2NCLScBxY0yPAOi2QF/OOaiD4B5jzDkRiXB/URwEByKSGdUcCwDTjDH/2v5J6IdovknFF8UVmeD2vyZqmtmGapT7gaOoZrvNGPN+avHiIAGOcAwCbExkvA356YoGeU+3QjMLkMUYsz9Amregw72bjTF/i0h6Y8z54HPvwBNEpCPqELsrNTVZ95AtEakNHDLG/CEiZVDzyWF0ooArO/n3xphdqcWPgwQ4wjHIcIuJzAl8ZvyMifRCqwU63GtsrlAA9PUOEcmDRhT0QQXjz6l4LnfBOACd7XISTRgxEXVQTQVGG2M+TC0+HHiGY3MMMowxv6PG/P2otzMltGah87Bni0gal+3SQariOBqS1To1BSNcMhOnNZphqTwa7lUCzeq+F7VdDxSRG53f/8rC0RxTCSKS1hhzIUi0MhtjTgeDloPQQ0RyG2MO2eVsaHhXVWNMadvXAHXM/I0OqeOMMf+Fit/rFY7mmEoIlmC0tBzBeI1AREoDB0TkDRHpZYw5gc6k2iwiYwGMMUvR0LCs6IwlRzCGAI7m6MDBFYSIFEBtitPRiQF70fRwx9DZUBmMMQ/bfTMYY86FitfrHY7m6MDBFYQxZg86A6oqOuV0PhrhMBJNG9dARJ6yuzvRCSGEIxwdOLhCcHOoDAEMGtGwH60vvR6tFX4G+A4SHDYOQgMnn6MDB1cIrkBvNLB7B/AGqkE+YoyZKiJFgBN2ppSDEMOxOTpwEALYGVXLgP8ZY14MNT8OLoczrHbgIAQwxmxHh9cRIpIx1Pw4uByOcHTgIHT4CbU3OghDOMNqBw5CCPfSDA7CC45wdODAgQMPcIbVDhw4cOABjnB04MCBAw9whKMDBw4ceIAjHB04cODAAxzh6CBVISKn7f+8IjI5iX0fDjTmT0QaiciMAPZfLCLRgZzDwfUJRzg6CBgiEhHoMcaY/caYDkns9jDgBEQ7CAs4wtHBRYhIYRH5VUQ+EZHNIjLZpcmJyG4RGSYiy4GOIlJMRGaLSIyILLN5ChGRIiLyk4isFZEXE9H+2S5HiMhoEdlizzNIRB5Ei4ktEpFFdr9mltZ6EfnWFsJCRJpbPpcD7bxcy2Xn8LDPeyKyTkS2isjzbv0jRWSbPW607esoIj+LyCYRWep2jlH2WjeLSD/bn0dElorIRntM/ZT/Og6uOEJdG9Zp4dPQsqQGqGvXPwQes8u7gSfc9l0AlLDLNYGFdnk60M0u3w+cdqP9s10egGaeibTrN7idI6ddzonWjc5k14cAw9AKfHvQUgKCFqGa4eFavJ1jMRCdqC/C9ldEi1htJyEGOLv9vwXIl6ivL/CMXY4C1gFF0FIHQ91oZwn1b+u0wJujOTpIjD1G62OD1m+u57bta7hYyrQO8K2IbATGo8WgAOoCX9rlT72c4xZgnLE1vI3nLDS1gLLACnuO7kAhtND9LmPM70alz2cpOEcnEVkPbADK2fOdRPMoThSRdoBr9soK4GMR6YMKPIBmQDfL32rgRlRorwXuE5HhQAVjzCkvPDoIYzgpyxwkRuIpU+7rZ+z/NGgt7sp+0kgM8XOfecaYzpd0ilT249gkz2HTgz0GVDfGHBORj4H0xphYEamBZum+G3gAaGKM6S9aT7olsNHyIcAgY8wcD/Qb2H0/FZFRxphJfvDsIIzgaI4OEqOgrZ8MWuRpeeIdjDEngV2itZ0RRSW7eQUqVEAr53nCXKC/iETa42+w/aeALHZ5FVBXRIrbfTKKSEngV6CIiBRz4zGQc7iQFRX2J0QkN1qiwKUVZzPG/Ig6iCrb/mLGmNXGmGHAEaAAMAcYICJp7T4lRSSTiBQC/jbGvA98gOZsdHCVwRGODhLjF6C7iGxG7W/vednvHqCXiGwCtqJZrAHaAekDAAAAv0lEQVQeAu4XkbVANi/HTgT+QotKbULrfANMAGaJyCJjzGGgB/Cl5WUVUNoYcx619c20Dpk/AzwHAMaYTehweitqW3WZErIAM+w5lwCP2P5R1rnzM2oL3WTPsQ1Yb/vHo6OxRqh2uQFoD4zxwqODMIaTeMLBRYhIYdS5UT7ErDhwEHI4mqMDBw4ceICjOTpw4MCBBziaowMHDhx4gCMcHThw4MADHOHowIEDBx7gCEcHDhw48ABHODpw4MCBB/wf05wiemboXegAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = LinearSVC()\n",
    "m.fit(X_train_500.reshape(-1,784), y_train_500)\n",
    "plot_confusion_mat(m, X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix_norm(m, X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08, 1.e+09,\n",
       "       1.e+10])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-6,10,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treffer\n"
     ]
    }
   ],
   "source": [
    "b = np.logspace(-6,10,17)\n",
    "if 10**-6 in b:\n",
    "    print(\"treffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.562e-02, 3.125e-02, 6.250e-02, 1.250e-01, 2.500e-01, 5.000e-01,\n",
       "       1.000e+00, 2.000e+00, 4.000e+00, 8.000e+00, 1.600e+01, 3.200e+01,\n",
       "       6.400e+01, 1.280e+02, 2.560e+02, 5.120e+02, 1.024e+03])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-6,10,17,base=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.562e-02 3.125e-02 6.250e-02 1.250e-01 2.500e-01 5.000e-01 1.000e+00\n",
      " 2.000e+00 4.000e+00 8.000e+00 1.600e+01 3.200e+01 6.400e+01 1.280e+02\n",
      " 2.560e+02 5.120e+02 1.024e+03]\n"
     ]
    }
   ],
   "source": [
    "c=np.logspace(-6,10,17,base=2.0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4,2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tuning der Hyperparameter mit GridSearchCV\n",
    "'''\n",
    "\n",
    "def tuning_hyper_params(X, y, kernel, cv, scoring, c_range, gamma_range):\n",
    "    \n",
    "    param_grid=[]\n",
    "    scores = scoring\n",
    "    if kernel == 'linear':\n",
    "        param_grid = [{'kernel':['linear'],\n",
    "                     'C': c_range}]\n",
    "    elif kernel == 'poly':\n",
    "        param_grid = [{'kernel':['poly'],\n",
    "                      'C': c_range,\n",
    "                      'gamma': gamma_range,\n",
    "                      'degree': [1,2,3]}]\n",
    "        \n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = [{'kernel': ['rbf'],\n",
    "                     'C': c_range,\n",
    "                      'gamma': gamma_range}]\n",
    "    elif kernel == 'sigmoid':\n",
    "        param_grid = [{'kernel': ['sigmoid'],\n",
    "                      'C': c_range,\n",
    "                      'gamma': gamma_range}]\n",
    "    else:\n",
    "        print(\"Fehlerhafte Eingabe\")\n",
    "        \n",
    "    \n",
    "    print(\"Tuning Hyperparameter zu Score\", scoring)\n",
    "    print()\n",
    "    clf = GridSearchCV(SVC(), param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    start=time.time()\n",
    "    start2 = time.process_time()\n",
    "    start3 = time.perf_counter()\n",
    "    clf.fit(X,y)\n",
    "    print(\"Zeit für Suche: \", time.time()-start)\n",
    "    print(\"Zeit für Suche: \", time.process_time()-start2)\n",
    "    print(\"Zeit für Suche: \", time.perf_counter()-start3)\n",
    "        \n",
    "    print(\"Besten gefundenen Parameter lauten:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    #params = clf.cv_results_['params']\n",
    "    \n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "     #   print(\"%f (%f) mit: %r\" % (mean, stdev, param))\n",
    "        \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "             % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Klassifikationsreport\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test.reshape(-1,784))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    return clf                             \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tuning des Hyperparameters C von LinearSVC\n",
    "'''\n",
    "\n",
    "def tuning_hyper_param_LinearSVC(X, y, cv, scoring, c_range):\n",
    "    param_grid=[{'C': c_range}]\n",
    "    print(\"Tuning des Hyperparameters C zu Score\", scoring)\n",
    "    print()\n",
    "    clf=GridSearchCV(LinearSVC(), param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    start=time.time()\n",
    "    start2 = time.process_time()\n",
    "    start3 = time.perf_counter()\n",
    "    clf.fit(X,y)\n",
    "    print(\"Zeit für Suche: \", time.time()-start)\n",
    "    print(\"Zeit für Suche: \", time.process_time()-start2)\n",
    "    print(\"Zeit für Suche: \", time.perf_counter()-start3)\n",
    "        \n",
    "    print(\"Besten gefundenen Parameter lauten:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "            \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "             % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Klassifikationsreport\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test.reshape(-1,784))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    return clf                             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 500\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  15.03300952911377\n",
      "Zeit für Suche:  0.9516060999999922\n",
      "Zeit für Suche:  15.033921004026524\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "0.658 (+/-0.043) for {'C': 0.0001}\n",
      "0.706 (+/-0.047) for {'C': 0.001}\n",
      "0.776 (+/-0.073) for {'C': 0.01}\n",
      "0.778 (+/-0.048) for {'C': 0.1}\n",
      "0.764 (+/-0.037) for {'C': 1.0}\n",
      "0.758 (+/-0.043) for {'C': 10.0}\n",
      "0.760 (+/-0.033) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.82      0.80      1000\n",
      "           4       0.60      0.71      0.65      1000\n",
      "           5       0.88      0.80      0.84      1000\n",
      "           6       0.55      0.42      0.48      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.89      0.90      0.89      1000\n",
      "           9       0.84      0.90      0.87      1000\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_500= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   5, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv5_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  26.710525274276733\n",
      "Zeit für Suche:  1.0920069999999669\n",
      "Zeit für Suche:  26.71311504638561\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "0.662 (+/-0.052) for {'C': 0.0001}\n",
      "0.704 (+/-0.056) for {'C': 0.001}\n",
      "0.772 (+/-0.097) for {'C': 0.01}\n",
      "0.780 (+/-0.101) for {'C': 0.1}\n",
      "0.764 (+/-0.094) for {'C': 1.0}\n",
      "0.762 (+/-0.090) for {'C': 10.0}\n",
      "0.764 (+/-0.089) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.82      0.80      1000\n",
      "           4       0.60      0.71      0.65      1000\n",
      "           5       0.88      0.80      0.84      1000\n",
      "           6       0.55      0.42      0.48      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.89      0.90      0.89      1000\n",
      "           9       0.84      0.90      0.87      1000\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.78      0.77      0.77     10000\n",
      "weighted avg       0.78      0.77      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_500= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   10, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv10_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  18.827457904815674\n",
      "Zeit für Suche:  0.4836030999999821\n",
      "Zeit für Suche:  18.835234875124115\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.772 (+/-0.097) for {'C': 0.01}\n",
      "0.788 (+/-0.115) for {'C': 0.03162277660168379}\n",
      "0.780 (+/-0.101) for {'C': 0.1}\n",
      "0.770 (+/-0.092) for {'C': 0.31622776601683794}\n",
      "0.766 (+/-0.091) for {'C': 1.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.61      0.68      0.65      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.60      0.73      0.65      1000\n",
      "           5       0.90      0.80      0.85      1000\n",
      "           6       0.57      0.38      0.46      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.88      0.92      0.90      1000\n",
      "           9       0.84      0.91      0.87      1000\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning\n",
    "gs_linearSVC_cv10_500B= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   10, 'accuracy', np.logspace(-2,0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv10_500B.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  12.398997068405151\n",
      "Zeit für Suche:  0.5460034999999834\n",
      "Zeit für Suche:  12.40080321838468\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.772 (+/-0.097) for {'C': 0.01}\n",
      "0.790 (+/-0.098) for {'C': 0.01778279410038923}\n",
      "0.788 (+/-0.115) for {'C': 0.03162277660168379}\n",
      "0.780 (+/-0.129) for {'C': 0.05623413251903491}\n",
      "0.780 (+/-0.101) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.62      0.67      0.64      1000\n",
      "           3       0.77      0.83      0.80      1000\n",
      "           4       0.58      0.74      0.65      1000\n",
      "           5       0.92      0.78      0.85      1000\n",
      "           6       0.57      0.35      0.43      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.87      0.94      0.90      1000\n",
      "           9       0.83      0.93      0.87      1000\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning\n",
    "gs_linearSVC_cv10_500C= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   10, 'accuracy', np.logspace(-2,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  11.218955278396606\n",
      "Zeit für Suche:  0.5616036000000122\n",
      "Zeit für Suche:  11.227885155411968\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.772 (+/-0.097) for {'C': 0.01}\n",
      "0.778 (+/-0.097) for {'C': 0.01333521432163324}\n",
      "0.790 (+/-0.098) for {'C': 0.01778279410038923}\n",
      "0.790 (+/-0.092) for {'C': 0.023713737056616554}\n",
      "0.788 (+/-0.115) for {'C': 0.03162277660168379}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.62      0.67      0.64      1000\n",
      "           3       0.77      0.83      0.80      1000\n",
      "           4       0.58      0.74      0.65      1000\n",
      "           5       0.92      0.78      0.85      1000\n",
      "           6       0.57      0.35      0.43      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.87      0.94      0.90      1000\n",
      "           9       0.83      0.93      0.87      1000\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning\n",
    "gs_linearSVC_cv10_500D= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   10, 'accuracy', np.logspace(-2,-1.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  13.696622848510742\n",
      "Zeit für Suche:  0.46800300000001016\n",
      "Zeit für Suche:  13.69758637373343\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.772 (+/-0.097) for {'C': 0.01}\n",
      "0.780 (+/-0.091) for {'C': 0.012115276586285882}\n",
      "0.782 (+/-0.097) for {'C': 0.014677992676220698}\n",
      "0.790 (+/-0.098) for {'C': 0.01778279410038923}\n",
      "0.790 (+/-0.092) for {'C': 0.021544346900318832}\n",
      "0.788 (+/-0.098) for {'C': 0.026101572156825358}\n",
      "0.788 (+/-0.115) for {'C': 0.03162277660168379}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1000\n",
      "           1       0.97      0.94      0.95      1000\n",
      "           2       0.62      0.67      0.64      1000\n",
      "           3       0.77      0.83      0.80      1000\n",
      "           4       0.58      0.74      0.65      1000\n",
      "           5       0.92      0.78      0.85      1000\n",
      "           6       0.57      0.35      0.43      1000\n",
      "           7       0.83      0.86      0.85      1000\n",
      "           8       0.87      0.94      0.90      1000\n",
      "           9       0.83      0.93      0.87      1000\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.78      0.78      0.77     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning\n",
    "gs_linearSVC_cv10_500E= tuning_hyper_param_LinearSVC(X_train_500.reshape(-1,784),y_train_500,\n",
    "                                                   10, 'accuracy', np.logspace(-2,-1.5,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv10_500C.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  8.167435646057129\n",
      "Zeit für Suche:  0.5148032999999828\n",
      "Zeit für Suche:  8.165180876092359\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.662 (+/-0.056) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.760 (+/-0.047) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.798 (+/-0.070) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.762 (+/-0.043) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.762 (+/-0.043) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin_svc_cv5_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7867\n"
     ]
    }
   ],
   "source": [
    "print(gs_lin_svc_cv5_500.score(X_test.reshape(-1,784), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lin_500 = SVC(kernel='linear', C=0.1)\n",
    "svc_lin_500.fit(X_train_500.reshape(-1,784), y_train_500)\n",
    "svc_lin_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lin_500.score(X_train_500.reshape(-1,784), y_train_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.624 (+/-0.110) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.668 (+/-0.074) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.764 (+/-0.114) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.804 (+/-0.087) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.774 (+/-0.080) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.774 (+/-0.080) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.774 (+/-0.080) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin_svc_cv10_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 10, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.764 (+/-0.114) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.776 (+/-0.114) for {'C': 0.03162277660168379, 'kernel': 'linear'}\n",
      "0.804 (+/-0.087) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.776 (+/-0.089) for {'C': 0.31622776601683794, 'kernel': 'linear'}\n",
      "0.774 (+/-0.080) for {'C': 1.0, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetuning mit Parametern in engerer Nachbarschaft\n",
    "lin_svc_cv5_500_B = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 10, 'accuracy', np.logspace(-2,0,5), np.logspace(-2,0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  12.214698553085327\n",
      "Zeit für Suche:  0.6396041000000423\n",
      "Zeit für Suche:  12.215722608842043\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.776 (+/-0.114) for {'C': 0.03162277660168379, 'kernel': 'linear'}\n",
      "0.792 (+/-0.097) for {'C': 0.05623413251903491, 'kernel': 'linear'}\n",
      "0.804 (+/-0.087) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.788 (+/-0.080) for {'C': 0.1778279410038923, 'kernel': 'linear'}\n",
      "0.776 (+/-0.089) for {'C': 0.31622776601683794, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetuning mit Parametern in engerer Nachbarschaft\n",
    "lin_svc_cv5_500_C = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 10, 'accuracy', np.logspace(-1.5,-0.5,5), np.logspace(-1.5,-0.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  11.572662115097046\n",
      "Zeit für Suche:  0.7800049999999601\n",
      "Zeit für Suche:  11.573882962384232\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.792 (+/-0.097) for {'C': 0.05623413251903491, 'kernel': 'linear'}\n",
      "0.800 (+/-0.084) for {'C': 0.07498942093324558, 'kernel': 'linear'}\n",
      "0.804 (+/-0.087) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.792 (+/-0.084) for {'C': 0.1333521432163324, 'kernel': 'linear'}\n",
      "0.788 (+/-0.080) for {'C': 0.1778279410038923, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetuning mit Parametern in engerer Nachbarschaft\n",
    "lin_svc_cv5_500_D = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 10, 'accuracy', np.logspace(-1.25,-0.75,5), np.logspace(-1.25,-0.75,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  21.651238441467285\n",
      "Zeit für Suche:  0.8580054999999902\n",
      "Zeit für Suche:  21.652651204178255\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.792 (+/-0.097) for {'C': 0.05623413251903491, 'kernel': 'linear'}\n",
      "0.792 (+/-0.093) for {'C': 0.06309573444801933, 'kernel': 'linear'}\n",
      "0.796 (+/-0.085) for {'C': 0.0707945784384138, 'kernel': 'linear'}\n",
      "0.800 (+/-0.084) for {'C': 0.07943282347242814, 'kernel': 'linear'}\n",
      "0.800 (+/-0.088) for {'C': 0.08912509381337455, 'kernel': 'linear'}\n",
      "0.804 (+/-0.087) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.796 (+/-0.098) for {'C': 0.11220184543019636, 'kernel': 'linear'}\n",
      "0.794 (+/-0.098) for {'C': 0.12589254117941676, 'kernel': 'linear'}\n",
      "0.790 (+/-0.080) for {'C': 0.14125375446227545, 'kernel': 'linear'}\n",
      "0.788 (+/-0.084) for {'C': 0.15848931924611134, 'kernel': 'linear'}\n",
      "0.788 (+/-0.080) for {'C': 0.1778279410038923, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetuning mit Parametern in engerer Nachbarschaft\n",
    "lin_svc_cv5_500_E = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'linear', 10, 'accuracy', np.logspace(-1.25,-0.75,11), np.logspace(-1.25,-0.75,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  86.12806272506714\n",
      "Zeit für Suche:  1.357208700000001\n",
      "Zeit für Suche:  86.13413649768904\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.628 (+/-0.077) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.640 (+/-0.061) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.690 (+/-0.033) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.454 (+/-0.098) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.050) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.708 (+/-0.069) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.628 (+/-0.077) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.640 (+/-0.061) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.690 (+/-0.033) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.454 (+/-0.098) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.050) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.708 (+/-0.069) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.628 (+/-0.077) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.640 (+/-0.061) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.690 (+/-0.033) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.454 (+/-0.098) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.050) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.708 (+/-0.069) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.628 (+/-0.077) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.640 (+/-0.061) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.694 (+/-0.041) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.454 (+/-0.098) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.050) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.708 (+/-0.069) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.628 (+/-0.077) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.698 (+/-0.056) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.046) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.668 (+/-0.053) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.196 (+/-0.032) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.498 (+/-0.089) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.704 (+/-0.055) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.070) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.202 (+/-0.039) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.486 (+/-0.068) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.770 (+/-0.046) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.080) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.072) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.202 (+/-0.039) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.486 (+/-0.068) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.108 (+/-0.008) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.63      0.71      0.67      1000\n",
      "           3       0.76      0.81      0.78      1000\n",
      "           4       0.64      0.70      0.67      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.55      0.50      0.53      1000\n",
      "           7       0.88      0.88      0.88      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv5_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rbf_svc_cv5_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.003, 0.01 , 0.032, 0.1  ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3,-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  32.87566828727722\n",
      "Zeit für Suche:  0.7332046999999875\n",
      "Zeit für Suche:  32.891132342608216\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 3.1622776601683795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.698 (+/-0.056) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.756 (+/-0.037) for {'C': 1.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.046) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.043) for {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.668 (+/-0.053) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.027) for {'C': 3.1622776601683795, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.064) for {'C': 3.1622776601683795, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.060) for {'C': 3.1622776601683795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.039) for {'C': 3.1622776601683795, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 3.1622776601683795, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.066) for {'C': 10.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.070) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.042) for {'C': 10.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.053) for {'C': 31.622776601683793, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.054) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.072) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.042) for {'C': 31.622776601683793, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 31.622776601683793, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.080) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.054) for {'C': 100.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.072) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.042) for {'C': 100.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.67      0.66      0.67      1000\n",
      "           3       0.76      0.82      0.79      1000\n",
      "           4       0.62      0.73      0.67      1000\n",
      "           5       0.87      0.91      0.89      1000\n",
      "           6       0.53      0.48      0.51      1000\n",
      "           7       0.88      0.87      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.91      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning in der engeren Nachbarschaft\n",
    "gs_rbf_svc_cv5_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 5, 'accuracy', np.logspace(0,2,5), np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rbf_svc_cv5_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.   ,  1.778,  3.162,  5.623, 10.   ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  51.64501452445984\n",
      "Zeit für Suche:  0.9516060999999922\n",
      "Zeit für Suche:  51.659908615775294\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 3.1622776601683795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.698 (+/-0.056) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.740 (+/-0.025) for {'C': 1.0, 'gamma': 0.0021544346900318843, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.032) for {'C': 1.0, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.046) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.058) for {'C': 1.0, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.766 (+/-0.057) for {'C': 1.0, 'gamma': 0.046415888336127774, 'kernel': 'rbf'}\n",
      "0.668 (+/-0.053) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.039) for {'C': 1.7782794100389228, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.027) for {'C': 1.7782794100389228, 'gamma': 0.0021544346900318843, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.039) for {'C': 1.7782794100389228, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.060) for {'C': 1.7782794100389228, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.047) for {'C': 1.7782794100389228, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.066) for {'C': 1.7782794100389228, 'gamma': 0.046415888336127774, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 1.7782794100389228, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.027) for {'C': 3.1622776601683795, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.043) for {'C': 3.1622776601683795, 'gamma': 0.0021544346900318843, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.064) for {'C': 3.1622776601683795, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.060) for {'C': 3.1622776601683795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.027) for {'C': 3.1622776601683795, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.056) for {'C': 3.1622776601683795, 'gamma': 0.046415888336127774, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 3.1622776601683795, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.037) for {'C': 5.623413251903491, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.776 (+/-0.061) for {'C': 5.623413251903491, 'gamma': 0.0021544346900318843, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.066) for {'C': 5.623413251903491, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.045) for {'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.034) for {'C': 5.623413251903491, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.053) for {'C': 5.623413251903491, 'gamma': 0.046415888336127774, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 5.623413251903491, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.057) for {'C': 10.0, 'gamma': 0.0021544346900318843, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.067) for {'C': 10.0, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.070) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.034) for {'C': 10.0, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.053) for {'C': 10.0, 'gamma': 0.046415888336127774, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.061) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.67      0.66      0.67      1000\n",
      "           3       0.76      0.82      0.79      1000\n",
      "           4       0.62      0.73      0.67      1000\n",
      "           5       0.87      0.91      0.89      1000\n",
      "           6       0.53      0.48      0.51      1000\n",
      "           7       0.88      0.87      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.91      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finetuning in der engeren Nachbarschaft\n",
    "gs_rbf_svc_cv5_500C = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 5, 'accuracy', np.logspace(0,1,5), np.logspace(-3,-1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rbf_svc_cv5_500C.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  193.92609190940857\n",
      "Zeit für Suche:  2.012412900000072\n",
      "Zeit für Suche:  193.92860263017064\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.624 (+/-0.106) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.634 (+/-0.084) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.688 (+/-0.078) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.460 (+/-0.098) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.065) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.710 (+/-0.082) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.106) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.634 (+/-0.084) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.688 (+/-0.078) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.460 (+/-0.098) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.065) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.710 (+/-0.082) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.106) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.634 (+/-0.084) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.688 (+/-0.078) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.460 (+/-0.098) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.065) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.710 (+/-0.082) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.106) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.634 (+/-0.084) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.694 (+/-0.082) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.460 (+/-0.098) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.148 (+/-0.065) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.710 (+/-0.082) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.106) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.716 (+/-0.064) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.670 (+/-0.084) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.198 (+/-0.079) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.482 (+/-0.123) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.712 (+/-0.076) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.766 (+/-0.110) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.082) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.202 (+/-0.079) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.484 (+/-0.101) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.770 (+/-0.132) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.091) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.202 (+/-0.079) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.484 (+/-0.101) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.112 (+/-0.027) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.62      0.71      0.66      1000\n",
      "           3       0.76      0.81      0.78      1000\n",
      "           4       0.64      0.69      0.66      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.56      0.50      0.52      1000\n",
      "           7       0.88      0.88      0.88      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.80     10000\n",
      "weighted avg       0.80      0.79      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mit cv=10\n",
    "gs_rbf_svc_cv10_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 10, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  134.31368207931519\n",
      "Zeit für Suche:  2.262014499999964\n",
      "Zeit für Suche:  134.31395416687155\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.716 (+/-0.064) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.746 (+/-0.065) for {'C': 1.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.107) for {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.670 (+/-0.084) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.746 (+/-0.086) for {'C': 2.371373705661655, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.120) for {'C': 2.371373705661655, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.109) for {'C': 2.371373705661655, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.090) for {'C': 2.371373705661655, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 2.371373705661655, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.119) for {'C': 5.623413251903491, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.804 (+/-0.078) for {'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 5.623413251903491, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.109) for {'C': 13.33521432163324, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.078) for {'C': 13.33521432163324, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 13.33521432163324, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 13.33521432163324, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 13.33521432163324, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.074) for {'C': 31.622776601683793, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.104) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 31.622776601683793, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 31.622776601683793, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.099) for {'C': 74.98942093324558, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.106) for {'C': 74.98942093324558, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 74.98942093324558, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 74.98942093324558, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 74.98942093324558, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.090) for {'C': 177.82794100389228, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.106) for {'C': 177.82794100389228, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 177.82794100389228, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 177.82794100389228, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 177.82794100389228, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.086) for {'C': 421.6965034285823, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.106) for {'C': 421.6965034285823, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 421.6965034285823, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 421.6965034285823, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 421.6965034285823, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.086) for {'C': 1000.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.106) for {'C': 1000.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 1000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 1000.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.095) for {'C': 1000.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.66      0.69      0.67      1000\n",
      "           3       0.77      0.82      0.79      1000\n",
      "           4       0.63      0.72      0.68      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.53      0.50      0.51      1000\n",
      "           7       0.87      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.93      1000\n",
      "           9       0.91      0.91      0.91      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.80     10000\n",
      "weighted avg       0.80      0.79      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500B = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 10, 'accuracy', np.logspace(0,3,9), np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeit für Suche:  133.8016529083252\n",
      "Zeit für Suche:  2.3556151000000227\n",
      "Zeit für Suche:  133.8025420796148\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.746 (+/-0.065) for {'C': 1.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.088) for {'C': 1.0, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.099) for {'C': 1.0, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.107) for {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.088) for {'C': 1.539926526059492, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.112) for {'C': 1.539926526059492, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.115) for {'C': 1.539926526059492, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.115) for {'C': 1.539926526059492, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.095) for {'C': 1.539926526059492, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.120) for {'C': 2.371373705661655, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.115) for {'C': 2.371373705661655, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.109) for {'C': 2.371373705661655, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.100) for {'C': 2.371373705661655, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.090) for {'C': 2.371373705661655, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.116) for {'C': 3.651741272548377, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.104) for {'C': 3.651741272548377, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.090) for {'C': 3.651741272548377, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.090) for {'C': 3.651741272548377, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.102) for {'C': 3.651741272548377, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.094) for {'C': 5.623413251903491, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.804 (+/-0.078) for {'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.080) for {'C': 5.623413251903491, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 5.623413251903491, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.082) for {'C': 8.659643233600654, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.074) for {'C': 8.659643233600654, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.087) for {'C': 8.659643233600654, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 8.659643233600654, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 8.659643233600654, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.078) for {'C': 13.33521432163324, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.093) for {'C': 13.33521432163324, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 13.33521432163324, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 13.33521432163324, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 13.33521432163324, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.093) for {'C': 20.53525026457146, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.088) for {'C': 20.53525026457146, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 20.53525026457146, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 20.53525026457146, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 20.53525026457146, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.104) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.088) for {'C': 31.622776601683793, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 31.622776601683793, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 31.622776601683793, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.66      0.69      0.67      1000\n",
      "           3       0.77      0.82      0.79      1000\n",
      "           4       0.63      0.72      0.68      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.53      0.50      0.51      1000\n",
      "           7       0.87      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.93      1000\n",
      "           9       0.91      0.91      0.91      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.80     10000\n",
      "weighted avg       0.80      0.79      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500C = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 10, 'accuracy', np.logspace(0,1.5,9), np.logspace(-2.5,-1.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  205.59875965118408\n",
      "Zeit für Suche:  3.026419400000009\n",
      "Zeit für Suche:  205.5986959351212\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.746 (+/-0.065) for {'C': 1.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.081) for {'C': 1.0, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.095) for {'C': 1.0, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.100) for {'C': 1.0, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.097) for {'C': 1.0, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.107) for {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.084) for {'C': 1.4125375446227544, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.103) for {'C': 1.4125375446227544, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.756 (+/-0.098) for {'C': 1.4125375446227544, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.766 (+/-0.110) for {'C': 1.4125375446227544, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.116) for {'C': 1.4125375446227544, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.090) for {'C': 1.4125375446227544, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.095) for {'C': 1.4125375446227544, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.108) for {'C': 1.9952623149688795, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.112) for {'C': 1.9952623149688795, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.115) for {'C': 1.9952623149688795, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.116) for {'C': 1.9952623149688795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.106) for {'C': 1.9952623149688795, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.096) for {'C': 1.9952623149688795, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.093) for {'C': 1.9952623149688795, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.112) for {'C': 2.8183829312644537, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.121) for {'C': 2.8183829312644537, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.114) for {'C': 2.8183829312644537, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.116) for {'C': 2.8183829312644537, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.105) for {'C': 2.8183829312644537, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.078) for {'C': 2.8183829312644537, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.093) for {'C': 2.8183829312644537, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.116) for {'C': 3.9810717055349722, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.100) for {'C': 3.9810717055349722, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.109) for {'C': 3.9810717055349722, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.802 (+/-0.095) for {'C': 3.9810717055349722, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.086) for {'C': 3.9810717055349722, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.092) for {'C': 3.9810717055349722, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.101) for {'C': 3.9810717055349722, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.104) for {'C': 5.623413251903491, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.802 (+/-0.094) for {'C': 5.623413251903491, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.804 (+/-0.078) for {'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.092) for {'C': 5.623413251903491, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.100) for {'C': 5.623413251903491, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 5.623413251903491, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.090) for {'C': 7.943282347242813, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.097) for {'C': 7.943282347242813, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.069) for {'C': 7.943282347242813, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.090) for {'C': 7.943282347242813, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.090) for {'C': 7.943282347242813, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.098) for {'C': 7.943282347242813, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 7.943282347242813, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 11.220184543019636, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 11.220184543019636, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.093) for {'C': 11.220184543019636, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.080) for {'C': 11.220184543019636, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.087) for {'C': 11.220184543019636, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.098) for {'C': 11.220184543019636, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 11.220184543019636, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.078) for {'C': 15.848931924611133, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.086) for {'C': 15.848931924611133, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 15.848931924611133, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 15.848931924611133, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.087) for {'C': 15.848931924611133, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.098) for {'C': 15.848931924611133, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 15.848931924611133, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.101) for {'C': 22.38721138568339, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.096) for {'C': 22.38721138568339, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 22.38721138568339, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 22.38721138568339, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.087) for {'C': 22.38721138568339, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.098) for {'C': 22.38721138568339, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 22.38721138568339, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.104) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.095) for {'C': 31.622776601683793, 'gamma': 0.004641588833612777, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 31.622776601683793, 'gamma': 0.006812920690579615, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.087) for {'C': 31.622776601683793, 'gamma': 0.01467799267622069, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.098) for {'C': 31.622776601683793, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 31.622776601683793, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.66      0.69      0.67      1000\n",
      "           3       0.77      0.82      0.79      1000\n",
      "           4       0.63      0.72      0.68      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.53      0.50      0.51      1000\n",
      "           7       0.87      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.93      1000\n",
      "           9       0.91      0.91      0.91      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.80      0.79      0.80     10000\n",
      "weighted avg       0.80      0.79      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500D = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 10, 'accuracy', np.logspace(0,1.5,11), np.logspace(-2.5,-1.5,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  309.23968744277954\n",
      "Zeit für Suche:  4.992031999999995\n",
      "Zeit für Suche:  309.24001244822284\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 4.216965034285822, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.746 (+/-0.065) for {'C': 1.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.076) for {'C': 1.0, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.088) for {'C': 1.0, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.756 (+/-0.098) for {'C': 1.0, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.760 (+/-0.101) for {'C': 1.0, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.099) for {'C': 1.0, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.107) for {'C': 1.0, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.107) for {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.078) for {'C': 1.333521432163324, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.756 (+/-0.087) for {'C': 1.333521432163324, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.756 (+/-0.099) for {'C': 1.333521432163324, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.758 (+/-0.102) for {'C': 1.333521432163324, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.110) for {'C': 1.333521432163324, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.106) for {'C': 1.333521432163324, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.105) for {'C': 1.333521432163324, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.090) for {'C': 1.333521432163324, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.092) for {'C': 1.333521432163324, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.097) for {'C': 1.7782794100389228, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.115) for {'C': 1.7782794100389228, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.111) for {'C': 1.7782794100389228, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.770 (+/-0.113) for {'C': 1.7782794100389228, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.115) for {'C': 1.7782794100389228, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.119) for {'C': 1.7782794100389228, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.093) for {'C': 1.7782794100389228, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.090) for {'C': 1.7782794100389228, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.088) for {'C': 1.7782794100389228, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.120) for {'C': 2.371373705661655, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.113) for {'C': 2.371373705661655, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.115) for {'C': 2.371373705661655, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.776 (+/-0.113) for {'C': 2.371373705661655, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.109) for {'C': 2.371373705661655, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.093) for {'C': 2.371373705661655, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.100) for {'C': 2.371373705661655, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.096) for {'C': 2.371373705661655, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.090) for {'C': 2.371373705661655, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.770 (+/-0.120) for {'C': 3.1622776601683795, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.119) for {'C': 3.1622776601683795, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.120) for {'C': 3.1622776601683795, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 3.1622776601683795, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.092) for {'C': 3.1622776601683795, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.102) for {'C': 3.1622776601683795, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.091) for {'C': 3.1622776601683795, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.093) for {'C': 3.1622776601683795, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.095) for {'C': 3.1622776601683795, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.772 (+/-0.116) for {'C': 4.216965034285822, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.100) for {'C': 4.216965034285822, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.100) for {'C': 4.216965034285822, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.089) for {'C': 4.216965034285822, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.804 (+/-0.099) for {'C': 4.216965034285822, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.081) for {'C': 4.216965034285822, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.083) for {'C': 4.216965034285822, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.099) for {'C': 4.216965034285822, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 4.216965034285822, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.095) for {'C': 5.623413251903491, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.094) for {'C': 5.623413251903491, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.802 (+/-0.094) for {'C': 5.623413251903491, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.804 (+/-0.078) for {'C': 5.623413251903491, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.094) for {'C': 5.623413251903491, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.080) for {'C': 5.623413251903491, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.102) for {'C': 5.623413251903491, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 5.623413251903491, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.090) for {'C': 7.498942093324558, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.093) for {'C': 7.498942093324558, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.097) for {'C': 7.498942093324558, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.075) for {'C': 7.498942093324558, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.088) for {'C': 7.498942093324558, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.089) for {'C': 7.498942093324558, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 7.498942093324558, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 7.498942093324558, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 7.498942093324558, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.098) for {'C': 10.0, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.093) for {'C': 10.0, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 10.0, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.088) for {'C': 10.0, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.082) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 10.0, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 10.0, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 10.0, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 10.0, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.078) for {'C': 13.33521432163324, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 13.33521432163324, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.093) for {'C': 13.33521432163324, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.080) for {'C': 13.33521432163324, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 13.33521432163324, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 13.33521432163324, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 13.33521432163324, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 13.33521432163324, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 13.33521432163324, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.090) for {'C': 17.78279410038923, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.097) for {'C': 17.78279410038923, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.093) for {'C': 17.78279410038923, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.076) for {'C': 17.78279410038923, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 17.78279410038923, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 17.78279410038923, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 17.78279410038923, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 17.78279410038923, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 17.78279410038923, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.106) for {'C': 23.71373705661655, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.103) for {'C': 23.71373705661655, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.088) for {'C': 23.71373705661655, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.076) for {'C': 23.71373705661655, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 23.71373705661655, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 23.71373705661655, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 23.71373705661655, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 23.71373705661655, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 23.71373705661655, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.104) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.101) for {'C': 31.622776601683793, 'gamma': 0.004216965034285823, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.088) for {'C': 31.622776601683793, 'gamma': 0.005623413251903491, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.076) for {'C': 31.622776601683793, 'gamma': 0.007498942093324558, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.079) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.087) for {'C': 31.622776601683793, 'gamma': 0.01333521432163324, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.076) for {'C': 31.622776601683793, 'gamma': 0.01778279410038923, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.100) for {'C': 31.622776601683793, 'gamma': 0.023713737056616554, 'kernel': 'rbf'}\n",
      "0.792 (+/-0.105) for {'C': 31.622776601683793, 'gamma': 0.03162277660168379, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.67      0.66      0.67      1000\n",
      "           3       0.77      0.83      0.79      1000\n",
      "           4       0.63      0.73      0.68      1000\n",
      "           5       0.88      0.91      0.89      1000\n",
      "           6       0.53      0.49      0.51      1000\n",
      "           7       0.88      0.88      0.88      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.91      0.91      0.91      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500E = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'rbf', 10, 'accuracy', np.logspace(0,1.5,13), np.logspace(-2.5,-1.5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500E.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7949"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rbf_svc_cv10_500D.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.003, 0.004, 0.006, 0.007, 0.01 , 0.013, 0.018, 0.024, 0.032])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2.5,-1.5,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  187.19908142089844\n",
      "Zeit für Suche:  1.9656125999999858\n",
      "Zeit für Suche:  187.21002000954695\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "\n",
      "0.624 (+/-0.110) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.105) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.572 (+/-0.076) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.086 (+/-0.074) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.054 (+/-0.065) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.110) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.105) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.572 (+/-0.076) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.086 (+/-0.074) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.110) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.105) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.572 (+/-0.076) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.086 (+/-0.074) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.110) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.105) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.572 (+/-0.076) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.086 (+/-0.074) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.110) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.668 (+/-0.070) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.498 (+/-0.088) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.088 (+/-0.092) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.668 (+/-0.074) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.111) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.442 (+/-0.125) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.136 (+/-0.080) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.764 (+/-0.114) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.806 (+/-0.086) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.406 (+/-0.127) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.122 (+/-0.123) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.012) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.68      0.64      1000\n",
      "           3       0.77      0.81      0.79      1000\n",
      "           4       0.60      0.69      0.65      1000\n",
      "           5       0.87      0.88      0.88      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.89      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_sig_svc_cv10_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'sigmoid', 10, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  79.20970726013184\n",
      "Zeit für Suche:  1.1232071999999675\n",
      "Zeit für Suche:  79.22425482875184\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.063) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.082) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.087) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.062 (+/-0.065) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.063) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.082) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.087) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.063) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.082) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.087) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.063) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.082) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.102 (+/-0.087) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.666 (+/-0.043) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.524 (+/-0.069) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.096 (+/-0.055) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.662 (+/-0.056) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.450 (+/-0.089) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.142 (+/-0.050) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.047) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.794 (+/-0.072) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.400 (+/-0.096) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.122 (+/-0.046) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.68      0.64      1000\n",
      "           3       0.77      0.81      0.79      1000\n",
      "           4       0.60      0.69      0.65      1000\n",
      "           5       0.87      0.88      0.88      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.89      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'sigmoid', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  32.32726001739502\n",
      "Zeit für Suche:  0.7020045000000437\n",
      "Zeit für Suche:  32.32899333906562\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 1000.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "\n",
      "0.662 (+/-0.056) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.734 (+/-0.048) for {'C': 10.0, 'gamma': 0.00031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.764 (+/-0.041) for {'C': 10.0, 'gamma': 0.0031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.450 (+/-0.089) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.736 (+/-0.052) for {'C': 31.622776601683793, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.047) for {'C': 31.622776601683793, 'gamma': 0.00031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.778 (+/-0.059) for {'C': 31.622776601683793, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.742 (+/-0.061) for {'C': 31.622776601683793, 'gamma': 0.0031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.428 (+/-0.094) for {'C': 31.622776601683793, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.047) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.780 (+/-0.057) for {'C': 100.0, 'gamma': 0.00031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.794 (+/-0.072) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.694 (+/-0.111) for {'C': 100.0, 'gamma': 0.0031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.400 (+/-0.096) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.780 (+/-0.057) for {'C': 316.22776601683796, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.796 (+/-0.069) for {'C': 316.22776601683796, 'gamma': 0.00031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.054) for {'C': 316.22776601683796, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.686 (+/-0.124) for {'C': 316.22776601683796, 'gamma': 0.0031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.394 (+/-0.099) for {'C': 316.22776601683796, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.798 (+/-0.070) for {'C': 1000.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.046) for {'C': 1000.0, 'gamma': 0.00031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.050) for {'C': 1000.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.688 (+/-0.125) for {'C': 1000.0, 'gamma': 0.0031622776601683794, 'kernel': 'sigmoid'}\n",
      "0.392 (+/-0.105) for {'C': 1000.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500B = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'sigmoid', 5, 'accuracy', np.logspace(1,3,5), np.logspace(-4,-2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500B.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  72.13572669029236\n",
      "Zeit für Suche:  1.560009999999977\n",
      "Zeit für Suche:  72.14726183655057\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 10000.0, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "\n",
      "0.624 (+/-0.078) for {'C': 10.0, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 10.0, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.078) for {'C': 10.0, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.662 (+/-0.056) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.712 (+/-0.056) for {'C': 10.0, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.754 (+/-0.039) for {'C': 10.0, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.043) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.624 (+/-0.078) for {'C': 23.71373705661655, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.630 (+/-0.068) for {'C': 23.71373705661655, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.664 (+/-0.043) for {'C': 23.71373705661655, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.716 (+/-0.047) for {'C': 23.71373705661655, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.032) for {'C': 23.71373705661655, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.036) for {'C': 23.71373705661655, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.772 (+/-0.050) for {'C': 23.71373705661655, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.638 (+/-0.077) for {'C': 56.23413251903491, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.668 (+/-0.046) for {'C': 56.23413251903491, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.726 (+/-0.052) for {'C': 56.23413251903491, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.748 (+/-0.020) for {'C': 56.23413251903491, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.045) for {'C': 56.23413251903491, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.776 (+/-0.056) for {'C': 56.23413251903491, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.792 (+/-0.053) for {'C': 56.23413251903491, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.676 (+/-0.065) for {'C': 133.3521432163324, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.728 (+/-0.041) for {'C': 133.3521432163324, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.029) for {'C': 133.3521432163324, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.045) for {'C': 133.3521432163324, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.778 (+/-0.059) for {'C': 133.3521432163324, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.788 (+/-0.077) for {'C': 133.3521432163324, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.784 (+/-0.065) for {'C': 133.3521432163324, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.736 (+/-0.052) for {'C': 316.22776601683796, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.750 (+/-0.033) for {'C': 316.22776601683796, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.052) for {'C': 316.22776601683796, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.780 (+/-0.057) for {'C': 316.22776601683796, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.790 (+/-0.066) for {'C': 316.22776601683796, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.782 (+/-0.065) for {'C': 316.22776601683796, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.054) for {'C': 316.22776601683796, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.754 (+/-0.037) for {'C': 749.8942093324558, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.052) for {'C': 749.8942093324558, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.782 (+/-0.060) for {'C': 749.8942093324558, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.790 (+/-0.067) for {'C': 749.8942093324558, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.776 (+/-0.064) for {'C': 749.8942093324558, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.046) for {'C': 749.8942093324558, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.050) for {'C': 749.8942093324558, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.056) for {'C': 1778.2794100389228, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.780 (+/-0.057) for {'C': 1778.2794100389228, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.792 (+/-0.065) for {'C': 1778.2794100389228, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.774 (+/-0.071) for {'C': 1778.2794100389228, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.758 (+/-0.041) for {'C': 1778.2794100389228, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.046) for {'C': 1778.2794100389228, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.050) for {'C': 1778.2794100389228, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.788 (+/-0.056) for {'C': 4216.965034285822, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.792 (+/-0.073) for {'C': 4216.965034285822, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.768 (+/-0.075) for {'C': 4216.965034285822, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.043) for {'C': 4216.965034285822, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.042) for {'C': 4216.965034285822, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.046) for {'C': 4216.965034285822, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.050) for {'C': 4216.965034285822, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.798 (+/-0.070) for {'C': 10000.0, 'gamma': 1e-05, 'kernel': 'sigmoid'}\n",
      "0.768 (+/-0.075) for {'C': 10000.0, 'gamma': 2.1544346900318823e-05, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.043) for {'C': 10000.0, 'gamma': 4.641588833612782e-05, 'kernel': 'sigmoid'}\n",
      "0.762 (+/-0.043) for {'C': 10000.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.042) for {'C': 10000.0, 'gamma': 0.00021544346900318823, 'kernel': 'sigmoid'}\n",
      "0.760 (+/-0.046) for {'C': 10000.0, 'gamma': 0.00046415888336127773, 'kernel': 'sigmoid'}\n",
      "0.746 (+/-0.050) for {'C': 10000.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500C = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'sigmoid', 5, 'accuracy', np.logspace(1,4,9), np.logspace(-5,-3,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sig_svc_cv5_500C.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  168.073388338089\n",
      "Zeit für Suche:  3.1512201999999547\n",
      "Zeit für Suche:  168.0661567163272\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.0001, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 0.0001, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 0.0001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.0001, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.0001, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.0001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.0001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.730 (+/-0.062) for {'C': 0.0001, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.069) for {'C': 0.0001, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.0001, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.0001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.0001, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.0001, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.602 (+/-0.034) for {'C': 0.0001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.756 (+/-0.064) for {'C': 0.0001, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.0001, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.0001, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.001, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.001, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.001, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.001, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 0.001, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 0.001, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.798 (+/-0.070) for {'C': 0.001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.001, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.001, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.634 (+/-0.055) for {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.754 (+/-0.069) for {'C': 0.001, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.001, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.001, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.001, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.672 (+/-0.065) for {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.001, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.001, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.001, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.01, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.01, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.01, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 0.01, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 0.01, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.798 (+/-0.070) for {'C': 0.01, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 0.01, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.01, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.01, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.730 (+/-0.062) for {'C': 0.01, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.069) for {'C': 0.01, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.01, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.01, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.01, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.406 (+/-0.066) for {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.714 (+/-0.090) for {'C': 0.01, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.01, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.01, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.01, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.1, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 0.1, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 0.1, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 0.1, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.798 (+/-0.070) for {'C': 0.1, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 0.1, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 0.1, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 0.1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.634 (+/-0.055) for {'C': 0.1, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.754 (+/-0.069) for {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.1, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.1, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 0.1, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.602 (+/-0.034) for {'C': 0.1, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.756 (+/-0.064) for {'C': 0.1, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.1, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.1, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 0.1, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.624 (+/-0.078) for {'C': 1.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 1.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 1.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.796 (+/-0.069) for {'C': 1.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 1.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 1.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 1.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 1.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 1.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.730 (+/-0.062) for {'C': 1.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.762 (+/-0.069) for {'C': 1.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 1.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 1.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 1.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 1.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 1.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.672 (+/-0.065) for {'C': 1.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 1.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 1.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 1.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 1.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.662 (+/-0.056) for {'C': 10.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 10.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.796 (+/-0.069) for {'C': 10.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 10.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 10.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 10.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 10.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 10.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.634 (+/-0.055) for {'C': 10.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.754 (+/-0.069) for {'C': 10.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 10.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 10.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 10.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 10.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 10.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.406 (+/-0.066) for {'C': 10.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.714 (+/-0.090) for {'C': 10.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 10.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 10.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 10.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 10.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.760 (+/-0.047) for {'C': 100.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.798 (+/-0.070) for {'C': 100.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.043) for {'C': 100.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.464 (+/-0.088) for {'C': 100.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.730 (+/-0.062) for {'C': 100.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.762 (+/-0.069) for {'C': 100.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 100.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 100.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 100.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.762 (+/-0.073) for {'C': 100.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.346 (+/-0.056) for {'C': 100.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.602 (+/-0.034) for {'C': 100.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.756 (+/-0.064) for {'C': 100.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 100.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 100.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 100.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.728 (+/-0.096) for {'C': 100.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.99      0.93      0.96      1000\n",
      "           2       0.60      0.69      0.64      1000\n",
      "           3       0.78      0.81      0.79      1000\n",
      "           4       0.61      0.70      0.65      1000\n",
      "           5       0.87      0.88      0.87      1000\n",
      "           6       0.56      0.43      0.49      1000\n",
      "           7       0.86      0.88      0.87      1000\n",
      "           8       0.94      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_poly_svc_cv5_500 = tuning_hyper_params(X_train_500.reshape(-1,784), y_train_500, 'poly', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAININGSMENGE 1000\\n'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TRAININGSMENGE 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  53.93213129043579\n",
      "Zeit für Suche:  0.7332046999999875\n",
      "Zeit für Suche:  53.93044757685129\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.670 (+/-0.052) for {'C': 0.0001}\n",
      "0.740 (+/-0.046) for {'C': 0.001}\n",
      "0.808 (+/-0.051) for {'C': 0.01}\n",
      "0.790 (+/-0.085) for {'C': 0.1}\n",
      "0.764 (+/-0.067) for {'C': 1.0}\n",
      "0.753 (+/-0.079) for {'C': 10.0}\n",
      "0.755 (+/-0.082) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      1000\n",
      "           1       0.98      0.94      0.96      1000\n",
      "           2       0.63      0.70      0.66      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.64      0.75      0.69      1000\n",
      "           5       0.93      0.79      0.86      1000\n",
      "           6       0.63      0.42      0.50      1000\n",
      "           7       0.83      0.89      0.86      1000\n",
      "           8       0.89      0.93      0.91      1000\n",
      "           9       0.85      0.93      0.88      1000\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_1000= tuning_hyper_param_LinearSVC(X_train_1000.reshape(-1,784),y_train_1000,\n",
    "                                                   10, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  24.844284772872925\n",
      "Zeit für Suche:  1.0452066999999943\n",
      "Zeit für Suche:  24.836859789724258\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.740 (+/-0.046) for {'C': 0.001}\n",
      "0.774 (+/-0.061) for {'C': 0.0031622776601683794}\n",
      "0.808 (+/-0.051) for {'C': 0.01}\n",
      "0.810 (+/-0.072) for {'C': 0.03162277660168379}\n",
      "0.790 (+/-0.085) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.63      0.73      0.68      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.67      0.72      0.70      1000\n",
      "           5       0.92      0.83      0.87      1000\n",
      "           6       0.59      0.46      0.52      1000\n",
      "           7       0.85      0.90      0.87      1000\n",
      "           8       0.90      0.93      0.91      1000\n",
      "           9       0.87      0.91      0.89      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_1000B= tuning_hyper_param_LinearSVC(X_train_1000.reshape(-1,784),y_train_1000,\n",
    "                                                   10, 'accuracy', np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  35.160017013549805\n",
      "Zeit für Suche:  1.0140065000000504\n",
      "Zeit für Suche:  35.16632479976215\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.808 (+/-0.051) for {'C': 0.01}\n",
      "0.809 (+/-0.057) for {'C': 0.01778279410038923}\n",
      "0.810 (+/-0.072) for {'C': 0.03162277660168379}\n",
      "0.802 (+/-0.075) for {'C': 0.05623413251903491}\n",
      "0.790 (+/-0.085) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.63      0.73      0.68      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.67      0.72      0.70      1000\n",
      "           5       0.92      0.83      0.87      1000\n",
      "           6       0.59      0.46      0.52      1000\n",
      "           7       0.85      0.90      0.87      1000\n",
      "           8       0.90      0.93      0.91      1000\n",
      "           9       0.87      0.91      0.89      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_1000C= tuning_hyper_param_LinearSVC(X_train_1000.reshape(-1,784),y_train_1000,\n",
    "                                                   10, 'accuracy', np.logspace(-2,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  36.851640462875366\n",
      "Zeit für Suche:  1.2012077000000545\n",
      "Zeit für Suche:  36.85820938463257\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.808 (+/-0.051) for {'C': 0.01}\n",
      "0.808 (+/-0.061) for {'C': 0.014677992676220698}\n",
      "0.807 (+/-0.069) for {'C': 0.021544346900318832}\n",
      "0.810 (+/-0.072) for {'C': 0.03162277660168379}\n",
      "0.809 (+/-0.068) for {'C': 0.046415888336127774}\n",
      "0.796 (+/-0.084) for {'C': 0.06812920690579612}\n",
      "0.790 (+/-0.085) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.63      0.73      0.68      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.67      0.72      0.70      1000\n",
      "           5       0.92      0.83      0.87      1000\n",
      "           6       0.59      0.46      0.52      1000\n",
      "           7       0.85      0.90      0.87      1000\n",
      "           8       0.90      0.93      0.91      1000\n",
      "           9       0.87      0.91      0.89      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_1000C= tuning_hyper_param_LinearSVC(X_train_1000.reshape(-1,784),y_train_1000,\n",
    "                                                   10, 'accuracy', np.logspace(-2,-1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv10_1000C.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01 , 0.015, 0.022, 0.032, 0.046, 0.068, 0.1  ])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2,-1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4,2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  32.77337074279785\n",
      "Zeit für Suche:  0.9828063000000498\n",
      "Zeit für Suche:  32.774121472294155\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.684 (+/-0.033) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.777 (+/-0.041) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.801 (+/-0.044) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.780 (+/-0.067) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.780 (+/-0.067) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      1000\n",
      "           1       0.99      0.94      0.97      1000\n",
      "           2       0.63      0.74      0.68      1000\n",
      "           3       0.78      0.82      0.80      1000\n",
      "           4       0.69      0.70      0.69      1000\n",
      "           5       0.88      0.88      0.88      1000\n",
      "           6       0.57      0.49      0.53      1000\n",
      "           7       0.86      0.89      0.88      1000\n",
      "           8       0.94      0.93      0.94      1000\n",
      "           9       0.91      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin_svc_cv5_1000 = tuning_hyper_params(X_train_1000.reshape(-1,784), y_train_1000, 'linear', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lin_svc_cv5_1000.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score f1\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 568, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 605, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 635, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 720, in f1_score\n    sample_weight=sample_weight)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 834, in fbeta_score\n    sample_weight=sample_weight)\n  File \"C:\\Users\\Martins-Lapt\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1047, in precision_recall_fscore_support\n    \"choose another average setting.\" % y_type)\nValueError: Target is multiclass but average='binary'. Please choose another average setting.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-c00f96f34792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs_lin_svc_cv5_1000_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuning_hyper_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_1000\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-145-ed869a2f6be2>\u001b[0m in \u001b[0;36mtuning_hyper_params\u001b[1;34m(X, y, kernel, cv, scoring, c_range, gamma_range)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mstart2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mstart3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Zeit für Suche: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Zeit für Suche: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "gs_lin_svc_cv5_1000_f1 = tuning_hyper_params(X_train_1000.reshape(-1,784), y_train_1000, 'linear', 5, 'f1', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  338.7347061634064\n",
      "Zeit für Suche:  1.8876120999999557\n",
      "Zeit für Suche:  338.73595745560306\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.629 (+/-0.037) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.029) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.436 (+/-0.085) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.134 (+/-0.031) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.041) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.629 (+/-0.037) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.029) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.436 (+/-0.085) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.134 (+/-0.031) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.041) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.613 (+/-0.051) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.629 (+/-0.037) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.029) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.436 (+/-0.085) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.134 (+/-0.031) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.041) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.613 (+/-0.051) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.629 (+/-0.037) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.693 (+/-0.026) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.436 (+/-0.085) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.134 (+/-0.031) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.041) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.047) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.718 (+/-0.027) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.787 (+/-0.028) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.664 (+/-0.077) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.212 (+/-0.026) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.323 (+/-0.164) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.727 (+/-0.042) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.042) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.817 (+/-0.010) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.684 (+/-0.065) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.222 (+/-0.036) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.308 (+/-0.150) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.801 (+/-0.047) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.039) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.815 (+/-0.023) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.684 (+/-0.065) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.222 (+/-0.036) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.308 (+/-0.150) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.118 (+/-0.015) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      1000\n",
      "           1       0.99      0.94      0.96      1000\n",
      "           2       0.65      0.74      0.69      1000\n",
      "           3       0.81      0.81      0.81      1000\n",
      "           4       0.69      0.71      0.70      1000\n",
      "           5       0.91      0.92      0.91      1000\n",
      "           6       0.59      0.53      0.56      1000\n",
      "           7       0.89      0.90      0.89      1000\n",
      "           8       0.95      0.95      0.95      1000\n",
      "           9       0.92      0.91      0.92      1000\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_svc_cv5_1000 = tuning_hyper_params(X_train_1000.reshape(-1,784), y_train_1000, 'rbf', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  354.4841992855072\n",
      "Zeit für Suche:  1.5132097000000044\n",
      "Zeit für Suche:  354.4767880341451\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.618 (+/-0.045) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.053) for {'C': 0.0001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.122 (+/-0.043) for {'C': 0.0001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.060 (+/-0.018) for {'C': 0.0001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.0001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.618 (+/-0.045) for {'C': 0.001, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.053) for {'C': 0.001, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.122 (+/-0.043) for {'C': 0.001, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 0.001, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.001, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.613 (+/-0.051) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.618 (+/-0.045) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.566 (+/-0.053) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.122 (+/-0.043) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.613 (+/-0.051) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.618 (+/-0.045) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.573 (+/-0.049) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.115 (+/-0.036) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.613 (+/-0.051) for {'C': 1.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.686 (+/-0.031) for {'C': 1.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.429 (+/-0.041) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.124 (+/-0.077) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.684 (+/-0.033) for {'C': 10.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.779 (+/-0.037) for {'C': 10.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.405 (+/-0.014) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.125 (+/-0.037) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "0.777 (+/-0.041) for {'C': 100.0, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "0.795 (+/-0.021) for {'C': 100.0, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "0.378 (+/-0.020) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.133 (+/-0.079) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.045 (+/-0.026) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'sigmoid'}\n",
      "0.100 (+/-0.000) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'sigmoid'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75      1000\n",
      "           1       0.99      0.94      0.97      1000\n",
      "           2       0.60      0.72      0.66      1000\n",
      "           3       0.78      0.83      0.80      1000\n",
      "           4       0.69      0.70      0.69      1000\n",
      "           5       0.88      0.88      0.88      1000\n",
      "           6       0.54      0.45      0.49      1000\n",
      "           7       0.86      0.89      0.87      1000\n",
      "           8       0.94      0.93      0.93      1000\n",
      "           9       0.91      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.79     10000\n",
      "weighted avg       0.80      0.80      0.79     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_sig_svc_cv5_1000 = tuning_hyper_params(X_train_1000.reshape(-1,784), y_train_1000, 'sigmoid', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameter zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  726.5227403640747\n",
      "Zeit für Suche:  3.7284238999999957\n",
      "Zeit für Suche:  726.5228002667936\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.0001, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 0.0001, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 0.0001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.0001, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.0001, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.0001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.455 (+/-0.017) for {'C': 0.0001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.750 (+/-0.030) for {'C': 0.0001, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.794 (+/-0.040) for {'C': 0.0001, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.0001, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.0001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.0001, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.0001, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.623 (+/-0.050) for {'C': 0.0001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.775 (+/-0.047) for {'C': 0.0001, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.0001, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.0001, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.001, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 0.001, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 0.001, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 0.001, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.001, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.001, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.648 (+/-0.034) for {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.800 (+/-0.033) for {'C': 0.001, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.001, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.001, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.001, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.711 (+/-0.045) for {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.774 (+/-0.022) for {'C': 0.001, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.001, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.001, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.01, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.01, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.01, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 0.01, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 0.01, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 0.01, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 0.01, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.01, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.01, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.455 (+/-0.017) for {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.750 (+/-0.030) for {'C': 0.01, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.794 (+/-0.040) for {'C': 0.01, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.01, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.01, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.01, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.442 (+/-0.027) for {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.765 (+/-0.022) for {'C': 0.01, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.01, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.01, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.01, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.1, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 0.1, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 0.1, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 0.1, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 0.1, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 0.1, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 0.1, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 0.1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.648 (+/-0.034) for {'C': 0.1, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.800 (+/-0.033) for {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.1, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.1, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 0.1, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.623 (+/-0.050) for {'C': 0.1, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.775 (+/-0.047) for {'C': 0.1, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.1, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.1, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 0.1, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.613 (+/-0.051) for {'C': 1.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 1.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 1.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 1.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 1.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 1.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 1.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 1.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.455 (+/-0.017) for {'C': 1.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.750 (+/-0.030) for {'C': 1.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.794 (+/-0.040) for {'C': 1.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 1.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 1.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 1.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 1.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 1.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.711 (+/-0.045) for {'C': 1.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.774 (+/-0.022) for {'C': 1.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 1.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 1.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 1.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.684 (+/-0.033) for {'C': 10.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 10.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 10.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 10.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 10.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 10.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 10.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.419 (+/-0.032) for {'C': 10.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.648 (+/-0.034) for {'C': 10.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.800 (+/-0.033) for {'C': 10.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 10.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 10.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 10.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 10.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 10.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.442 (+/-0.027) for {'C': 10.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.765 (+/-0.022) for {'C': 10.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 10.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 10.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 10.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 10.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.777 (+/-0.041) for {'C': 100.0, 'degree': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.801 (+/-0.044) for {'C': 100.0, 'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'degree': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'degree': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'degree': 1, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.780 (+/-0.067) for {'C': 100.0, 'degree': 1, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.455 (+/-0.017) for {'C': 100.0, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.750 (+/-0.030) for {'C': 100.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.794 (+/-0.040) for {'C': 100.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 100.0, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 100.0, 'degree': 2, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 100.0, 'degree': 2, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 100.0, 'degree': 2, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "0.312 (+/-0.039) for {'C': 100.0, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.623 (+/-0.050) for {'C': 100.0, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.775 (+/-0.047) for {'C': 100.0, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 100.0, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 100.0, 'degree': 3, 'gamma': 1.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 100.0, 'degree': 3, 'gamma': 10.0, 'kernel': 'poly'}\n",
      "0.772 (+/-0.008) for {'C': 100.0, 'degree': 3, 'gamma': 100.0, 'kernel': 'poly'}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      1000\n",
      "           1       0.99      0.94      0.97      1000\n",
      "           2       0.63      0.74      0.68      1000\n",
      "           3       0.78      0.82      0.80      1000\n",
      "           4       0.69      0.70      0.70      1000\n",
      "           5       0.88      0.88      0.88      1000\n",
      "           6       0.57      0.49      0.53      1000\n",
      "           7       0.86      0.89      0.88      1000\n",
      "           8       0.94      0.93      0.94      1000\n",
      "           9       0.91      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_poly_svc_cv5_1000 = tuning_hyper_params(X_train_1000.reshape(-1,784), y_train_1000, 'poly', 5, 'accuracy', np.logspace(-4,2,7), np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 2000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  55.5107536315918\n",
      "Zeit für Suche:  4.0248258000000305\n",
      "Zeit für Suche:  55.51380245414839\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "0.671 (+/-0.023) for {'C': 0.0001}\n",
      "0.765 (+/-0.043) for {'C': 0.001}\n",
      "0.809 (+/-0.026) for {'C': 0.01}\n",
      "0.815 (+/-0.021) for {'C': 0.1}\n",
      "0.785 (+/-0.021) for {'C': 1.0}\n",
      "0.776 (+/-0.028) for {'C': 10.0}\n",
      "0.777 (+/-0.021) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.66      0.73      0.70      1000\n",
      "           3       0.78      0.84      0.81      1000\n",
      "           4       0.70      0.69      0.70      1000\n",
      "           5       0.92      0.86      0.89      1000\n",
      "           6       0.58      0.50      0.54      1000\n",
      "           7       0.86      0.91      0.89      1000\n",
      "           8       0.91      0.91      0.91      1000\n",
      "           9       0.90      0.91      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  46.25319504737854\n",
      "Zeit für Suche:  1.9344123999999852\n",
      "Zeit für Suche:  46.26893511768685\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.809 (+/-0.026) for {'C': 0.01}\n",
      "0.819 (+/-0.026) for {'C': 0.03162277660168379}\n",
      "0.815 (+/-0.021) for {'C': 0.1}\n",
      "0.797 (+/-0.026) for {'C': 0.31622776601683794}\n",
      "0.787 (+/-0.022) for {'C': 1.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.68      0.73      0.70      1000\n",
      "           3       0.78      0.86      0.82      1000\n",
      "           4       0.71      0.71      0.71      1000\n",
      "           5       0.93      0.87      0.90      1000\n",
      "           6       0.61      0.51      0.55      1000\n",
      "           7       0.86      0.91      0.88      1000\n",
      "           8       0.91      0.92      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000B= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-2,0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  35.4576153755188\n",
      "Zeit für Suche:  3.2760210000000143\n",
      "Zeit für Suche:  35.46330124295855\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.05623413251903491}\n",
      "\n",
      "0.809 (+/-0.026) for {'C': 0.01}\n",
      "0.813 (+/-0.018) for {'C': 0.01778279410038923}\n",
      "0.819 (+/-0.026) for {'C': 0.03162277660168379}\n",
      "0.819 (+/-0.025) for {'C': 0.05623413251903491}\n",
      "0.815 (+/-0.021) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.67      0.74      0.70      1000\n",
      "           3       0.78      0.85      0.81      1000\n",
      "           4       0.70      0.70      0.70      1000\n",
      "           5       0.93      0.87      0.90      1000\n",
      "           6       0.60      0.51      0.55      1000\n",
      "           7       0.86      0.91      0.89      1000\n",
      "           8       0.91      0.92      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000C= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-2,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  43.637042760849\n",
      "Zeit für Suche:  2.340014999999994\n",
      "Zeit für Suche:  43.62778595863165\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.042169650342858224}\n",
      "\n",
      "0.819 (+/-0.026) for {'C': 0.03162277660168379}\n",
      "0.820 (+/-0.027) for {'C': 0.042169650342858224}\n",
      "0.819 (+/-0.025) for {'C': 0.05623413251903491}\n",
      "0.819 (+/-0.023) for {'C': 0.07498942093324558}\n",
      "0.815 (+/-0.021) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.67      0.73      0.70      1000\n",
      "           3       0.78      0.85      0.82      1000\n",
      "           4       0.70      0.71      0.70      1000\n",
      "           5       0.93      0.87      0.90      1000\n",
      "           6       0.61      0.51      0.55      1000\n",
      "           7       0.86      0.91      0.89      1000\n",
      "           8       0.91      0.92      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000D= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-1.5,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000D.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  34.6519820690155\n",
      "Zeit für Suche:  2.1996140999999625\n",
      "Zeit für Suche:  34.653576311418874\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.042169650342858224}\n",
      "\n",
      "0.819 (+/-0.026) for {'C': 0.03162277660168379}\n",
      "0.818 (+/-0.024) for {'C': 0.03651741272548377}\n",
      "0.820 (+/-0.027) for {'C': 0.042169650342858224}\n",
      "0.820 (+/-0.026) for {'C': 0.04869675251658631}\n",
      "0.819 (+/-0.025) for {'C': 0.05623413251903491}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.67      0.73      0.70      1000\n",
      "           3       0.78      0.85      0.82      1000\n",
      "           4       0.70      0.71      0.70      1000\n",
      "           5       0.93      0.87      0.90      1000\n",
      "           6       0.61      0.51      0.55      1000\n",
      "           7       0.86      0.91      0.89      1000\n",
      "           8       0.91      0.92      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000E= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-1.5,-1.25,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  36.89656639099121\n",
      "Zeit für Suche:  2.433615599999996\n",
      "Zeit für Suche:  36.89104116909584\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.042169650342858224}\n",
      "\n",
      "0.818 (+/-0.024) for {'C': 0.03651741272548377}\n",
      "0.818 (+/-0.026) for {'C': 0.03924189758484536}\n",
      "0.820 (+/-0.027) for {'C': 0.042169650342858224}\n",
      "0.819 (+/-0.028) for {'C': 0.04531583637600818}\n",
      "0.820 (+/-0.026) for {'C': 0.04869675251658631}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.67      0.73      0.70      1000\n",
      "           3       0.78      0.85      0.82      1000\n",
      "           4       0.70      0.71      0.70      1000\n",
      "           5       0.93      0.87      0.90      1000\n",
      "           6       0.61      0.51      0.55      1000\n",
      "           7       0.86      0.91      0.89      1000\n",
      "           8       0.91      0.92      0.92      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_2000F= tuning_hyper_param_LinearSVC(X_train_2000.reshape(-1,784),y_train_2000,\n",
    "                                                   5, 'accuracy', np.logspace(-1.4375,-1.3125,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.037, 0.039, 0.042, 0.045, 0.049])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-1.4375,-1.3125,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj = LinearSVC(C=0.018)\n",
    "jj.fit(X_train_2000.reshape(-1,784), y_train_2000)\n",
    "jj.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj = LinearSVC(C=0.042169650342858224)\n",
    "jj.fit(X_train_2000.reshape(-1,784), y_train_2000)\n",
    "jj.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 5000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  178.9140181541443\n",
      "Zeit für Suche:  2.932818800000007\n",
      "Zeit für Suche:  178.9236545423455\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.695 (+/-0.022) for {'C': 0.0001}\n",
      "0.803 (+/-0.021) for {'C': 0.001}\n",
      "0.831 (+/-0.011) for {'C': 0.01}\n",
      "0.819 (+/-0.019) for {'C': 0.1}\n",
      "0.785 (+/-0.018) for {'C': 1.0}\n",
      "0.763 (+/-0.023) for {'C': 10.0}\n",
      "0.758 (+/-0.022) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.74      0.72      1000\n",
      "           3       0.81      0.85      0.83      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.89      0.91      1000\n",
      "           6       0.65      0.48      0.55      1000\n",
      "           7       0.89      0.91      0.90      1000\n",
      "           8       0.90      0.95      0.93      1000\n",
      "           9       0.91      0.93      0.92      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.83      0.82     10000\n",
      "weighted avg       0.82      0.83      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_5000= tuning_hyper_param_LinearSVC(X_train_5000.reshape(-1,784),y_train_5000,\n",
    "                                                   5, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  89.31847023963928\n",
      "Zeit für Suche:  2.917218700000035\n",
      "Zeit für Suche:  89.329371000018\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.803 (+/-0.021) for {'C': 0.001}\n",
      "0.822 (+/-0.014) for {'C': 0.0031622776601683794}\n",
      "0.831 (+/-0.011) for {'C': 0.01}\n",
      "0.829 (+/-0.015) for {'C': 0.03162277660168379}\n",
      "0.819 (+/-0.019) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.74      0.72      1000\n",
      "           3       0.81      0.85      0.83      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.89      0.91      1000\n",
      "           6       0.65      0.48      0.55      1000\n",
      "           7       0.89      0.91      0.90      1000\n",
      "           8       0.90      0.95      0.93      1000\n",
      "           9       0.91      0.93      0.92      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.83      0.82     10000\n",
      "weighted avg       0.82      0.83      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv5_5000B= tuning_hyper_param_LinearSVC(X_train_5000.reshape(-1,784),y_train_5000,\n",
    "                                                   5, 'accuracy', np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.003, 0.01 , 0.032, 0.1  ])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3,-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  583.9465205669403\n",
      "Zeit für Suche:  2.9796191000000363\n",
      "Zeit für Suche:  583.9484918280141\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.699 (+/-0.026) for {'C': 0.0001}\n",
      "0.804 (+/-0.020) for {'C': 0.001}\n",
      "0.831 (+/-0.028) for {'C': 0.01}\n",
      "0.825 (+/-0.027) for {'C': 0.1}\n",
      "0.792 (+/-0.024) for {'C': 1.0}\n",
      "0.765 (+/-0.021) for {'C': 10.0}\n",
      "0.756 (+/-0.031) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.74      0.72      1000\n",
      "           3       0.81      0.85      0.83      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.89      0.91      1000\n",
      "           6       0.65      0.48      0.55      1000\n",
      "           7       0.89      0.91      0.90      1000\n",
      "           8       0.90      0.95      0.93      1000\n",
      "           9       0.91      0.93      0.92      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.83      0.82     10000\n",
      "weighted avg       0.82      0.83      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nochmal mit cv=10\n",
    "gs_linearSVC_cv10_5000= tuning_hyper_param_LinearSVC(X_train_5000.reshape(-1,784),y_train_5000,\n",
    "                                                   10, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  187.13670372962952\n",
      "Zeit für Suche:  3.08881980000001\n",
      "Zeit für Suche:  187.13805655351098\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.804 (+/-0.020) for {'C': 0.001}\n",
      "0.823 (+/-0.020) for {'C': 0.0031622776601683794}\n",
      "0.831 (+/-0.028) for {'C': 0.01}\n",
      "0.830 (+/-0.022) for {'C': 0.03162277660168379}\n",
      "0.825 (+/-0.027) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.74      0.72      1000\n",
      "           3       0.81      0.85      0.83      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.89      0.91      1000\n",
      "           6       0.65      0.48      0.55      1000\n",
      "           7       0.89      0.91      0.90      1000\n",
      "           8       0.90      0.95      0.93      1000\n",
      "           9       0.91      0.93      0.92      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.82      0.83      0.82     10000\n",
      "weighted avg       0.82      0.83      0.82     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv10_5000B= tuning_hyper_param_LinearSVC(X_train_5000.reshape(-1,784),y_train_5000,\n",
    "                                                   10, 'accuracy', np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 10000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  221.56744194030762\n",
      "Zeit für Suche:  5.912437899999986\n",
      "Zeit für Suche:  221.57819607735019\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.729 (+/-0.008) for {'C': 0.0001}\n",
      "0.818 (+/-0.005) for {'C': 0.001}\n",
      "0.838 (+/-0.009) for {'C': 0.01}\n",
      "0.836 (+/-0.004) for {'C': 0.1}\n",
      "0.809 (+/-0.016) for {'C': 1.0}\n",
      "0.783 (+/-0.015) for {'C': 10.0}\n",
      "0.768 (+/-0.050) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.71      1000\n",
      "           3       0.82      0.86      0.84      1000\n",
      "           4       0.71      0.77      0.73      1000\n",
      "           5       0.94      0.90      0.92      1000\n",
      "           6       0.65      0.48      0.56      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.92      0.94      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  112.1016776561737\n",
      "Zeit für Suche:  12.246078499999953\n",
      "Zeit für Suche:  112.11522062774384\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.818 (+/-0.005) for {'C': 0.001}\n",
      "0.834 (+/-0.009) for {'C': 0.0031622776601683794}\n",
      "0.838 (+/-0.009) for {'C': 0.01}\n",
      "0.838 (+/-0.010) for {'C': 0.03162277660168379}\n",
      "0.836 (+/-0.004) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.96      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.72      1000\n",
      "           3       0.81      0.86      0.84      1000\n",
      "           4       0.71      0.75      0.73      1000\n",
      "           5       0.93      0.91      0.92      1000\n",
      "           6       0.64      0.49      0.55      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.94      0.93      1000\n",
      "           9       0.93      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000B= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  153.80095911026\n",
      "Zeit für Suche:  8.48645440000007\n",
      "Zeit für Suche:  153.7933011376026\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.818 (+/-0.005) for {'C': 0.001}\n",
      "0.828 (+/-0.008) for {'C': 0.0017782794100389228}\n",
      "0.834 (+/-0.009) for {'C': 0.0031622776601683794}\n",
      "0.837 (+/-0.007) for {'C': 0.005623413251903491}\n",
      "0.838 (+/-0.009) for {'C': 0.01}\n",
      "0.839 (+/-0.012) for {'C': 0.01778279410038923}\n",
      "0.838 (+/-0.010) for {'C': 0.03162277660168379}\n",
      "0.838 (+/-0.008) for {'C': 0.05623413251903491}\n",
      "0.836 (+/-0.004) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.71      1000\n",
      "           3       0.81      0.86      0.84      1000\n",
      "           4       0.71      0.76      0.73      1000\n",
      "           5       0.93      0.90      0.92      1000\n",
      "           6       0.65      0.49      0.55      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.92      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000C= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-3,-1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  127.31695985794067\n",
      "Zeit für Suche:  8.283653099999924\n",
      "Zeit für Suche:  127.31879689864218\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.838 (+/-0.009) for {'C': 0.01}\n",
      "0.839 (+/-0.010) for {'C': 0.011547819846894581}\n",
      "0.839 (+/-0.012) for {'C': 0.01333521432163324}\n",
      "0.839 (+/-0.013) for {'C': 0.01539926526059492}\n",
      "0.839 (+/-0.012) for {'C': 0.01778279410038923}\n",
      "0.839 (+/-0.012) for {'C': 0.02053525026457146}\n",
      "0.839 (+/-0.011) for {'C': 0.023713737056616554}\n",
      "0.838 (+/-0.010) for {'C': 0.027384196342643614}\n",
      "0.838 (+/-0.010) for {'C': 0.03162277660168379}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.71      1000\n",
      "           3       0.81      0.86      0.84      1000\n",
      "           4       0.71      0.76      0.73      1000\n",
      "           5       0.93      0.90      0.92      1000\n",
      "           6       0.65      0.49      0.55      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.92      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000D= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-2,-1.5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  129.96637845039368\n",
      "Zeit für Suche:  9.391260200000033\n",
      "Zeit für Suche:  129.96011503260888\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.019109529749704406}\n",
      "\n",
      "0.839 (+/-0.012) for {'C': 0.01333521432163324}\n",
      "0.839 (+/-0.012) for {'C': 0.014330125702369627}\n",
      "0.839 (+/-0.013) for {'C': 0.01539926526059492}\n",
      "0.839 (+/-0.012) for {'C': 0.016548170999431813}\n",
      "0.839 (+/-0.012) for {'C': 0.01778279410038923}\n",
      "0.839 (+/-0.012) for {'C': 0.019109529749704406}\n",
      "0.839 (+/-0.012) for {'C': 0.02053525026457146}\n",
      "0.838 (+/-0.012) for {'C': 0.0220673406908459}\n",
      "0.839 (+/-0.011) for {'C': 0.023713737056616554}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1000\n",
      "           1       0.96      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.71      1000\n",
      "           3       0.81      0.86      0.84      1000\n",
      "           4       0.71      0.76      0.73      1000\n",
      "           5       0.93      0.90      0.92      1000\n",
      "           6       0.65      0.49      0.56      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.93      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000E= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-1.875,-1.625,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8315"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000E.score(X_test.reshape(-1,784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  127.45041131973267\n",
      "Zeit für Suche:  8.704855800000018\n",
      "Zeit für Suche:  127.45816837681014\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.019109529749704406}\n",
      "\n",
      "0.839 (+/-0.012) for {'C': 0.01778279410038923}\n",
      "0.839 (+/-0.011) for {'C': 0.01810558243027122}\n",
      "0.839 (+/-0.010) for {'C': 0.018434229924091106}\n",
      "0.839 (+/-0.011) for {'C': 0.018768842935762187}\n",
      "0.839 (+/-0.012) for {'C': 0.019109529749704406}\n",
      "0.839 (+/-0.012) for {'C': 0.019456400615886358}\n",
      "0.839 (+/-0.012) for {'C': 0.019809567785503388}\n",
      "0.839 (+/-0.012) for {'C': 0.020169145547303306}\n",
      "0.839 (+/-0.012) for {'C': 0.02053525026457146}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1000\n",
      "           1       0.96      0.95      0.96      1000\n",
      "           2       0.70      0.73      0.71      1000\n",
      "           3       0.81      0.86      0.84      1000\n",
      "           4       0.71      0.76      0.73      1000\n",
      "           5       0.93      0.90      0.92      1000\n",
      "           6       0.65      0.49      0.56      1000\n",
      "           7       0.89      0.92      0.91      1000\n",
      "           8       0.91      0.95      0.93      1000\n",
      "           9       0.93      0.93      0.93      1000\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_10000F= tuning_hyper_param_LinearSVC(X_train_10000.reshape(-1,784),y_train_10000,\n",
    "                                                   3, 'accuracy', np.logspace(-1.75,-1.6875,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.018, 0.018, 0.018, 0.019, 0.019, 0.019, 0.02 , 0.02 , 0.021])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-1.75,-1.6875,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.003, 0.01 , 0.032, 0.1  ])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3,-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 20000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameers C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  646.0853595733643\n",
      "Zeit für Suche:  12.168078000000037\n",
      "Zeit für Suche:  646.0792557161731\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "0.764 (+/-0.010) for {'C': 0.0001}\n",
      "0.828 (+/-0.012) for {'C': 0.001}\n",
      "0.843 (+/-0.011) for {'C': 0.01}\n",
      "0.839 (+/-0.013) for {'C': 0.1}\n",
      "0.822 (+/-0.015) for {'C': 1.0}\n",
      "0.788 (+/-0.034) for {'C': 10.0}\n",
      "0.772 (+/-0.006) for {'C': 100.0}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.73      0.72      1000\n",
      "           3       0.82      0.87      0.84      1000\n",
      "           4       0.71      0.76      0.73      1000\n",
      "           5       0.94      0.91      0.93      1000\n",
      "           6       0.65      0.51      0.57      1000\n",
      "           7       0.90      0.92      0.91      1000\n",
      "           8       0.92      0.95      0.93      1000\n",
      "           9       0.93      0.94      0.94      1000\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_20000= tuning_hyper_param_LinearSVC(X_train_20000.reshape(-1,784),y_train_20000,\n",
    "                                                   3, 'accuracy', np.logspace(-4,2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  235.587749004364\n",
      "Zeit für Suche:  29.608989799999904\n",
      "Zeit für Suche:  235.59947800124974\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.03162277660168379}\n",
      "\n",
      "0.828 (+/-0.012) for {'C': 0.001}\n",
      "0.839 (+/-0.008) for {'C': 0.0031622776601683794}\n",
      "0.843 (+/-0.011) for {'C': 0.01}\n",
      "0.843 (+/-0.009) for {'C': 0.03162277660168379}\n",
      "0.839 (+/-0.013) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.97      0.96      0.96      1000\n",
      "           2       0.71      0.74      0.73      1000\n",
      "           3       0.82      0.86      0.84      1000\n",
      "           4       0.72      0.76      0.74      1000\n",
      "           5       0.94      0.92      0.93      1000\n",
      "           6       0.65      0.52      0.58      1000\n",
      "           7       0.90      0.93      0.92      1000\n",
      "           8       0.92      0.95      0.94      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_20000B= tuning_hyper_param_LinearSVC(X_train_20000.reshape(-1,784),y_train_20000,\n",
    "                                                   3, 'accuracy', np.logspace(-3,-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning des Hyperparameters C zu Score accuracy\n",
      "\n",
      "Zeit für Suche:  324.0572295188904\n",
      "Zeit für Suche:  18.75132020000001\n",
      "Zeit für Suche:  324.05254552394763\n",
      "Besten gefundenen Parameter lauten:\n",
      "\n",
      "{'C': 0.01778279410038923}\n",
      "\n",
      "0.828 (+/-0.012) for {'C': 0.001}\n",
      "0.835 (+/-0.011) for {'C': 0.0017782794100389228}\n",
      "0.839 (+/-0.008) for {'C': 0.0031622776601683794}\n",
      "0.843 (+/-0.010) for {'C': 0.005623413251903491}\n",
      "0.843 (+/-0.011) for {'C': 0.01}\n",
      "0.844 (+/-0.009) for {'C': 0.01778279410038923}\n",
      "0.843 (+/-0.009) for {'C': 0.03162277660168379}\n",
      "0.841 (+/-0.011) for {'C': 0.05623413251903491}\n",
      "0.839 (+/-0.013) for {'C': 0.1}\n",
      "\n",
      "Klassifikationsreport\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.72      0.74      0.73      1000\n",
      "           3       0.83      0.86      0.84      1000\n",
      "           4       0.72      0.76      0.74      1000\n",
      "           5       0.94      0.92      0.93      1000\n",
      "           6       0.66      0.51      0.58      1000\n",
      "           7       0.90      0.93      0.91      1000\n",
      "           8       0.92      0.95      0.93      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_linearSVC_cv3_20000C= tuning_hyper_param_LinearSVC(X_train_20000.reshape(-1,784),y_train_20000,\n",
    "                                                   3, 'accuracy', np.logspace(-3,-1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.002, 0.003, 0.006, 0.01 , 0.018, 0.032, 0.056, 0.1  ])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3,-1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.003, 0.006, 0.01 , 0.018, 0.032, 0.056, 0.1  ])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2.5,-1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 30000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 40000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 50000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TRAININGSMENGE 60000\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
